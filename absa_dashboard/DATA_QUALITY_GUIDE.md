# ğŸ“Š Guide de QualitÃ© des DonnÃ©es pour Time Series

## ğŸ¯ ProblÃ¨me RÃ©solu

### Avant: DonnÃ©es de Mauvaise QualitÃ©
```
ProblÃ¨mes courants:
âŒ Jours avec seulement 1-2 reviews â†’ Moyenne non reprÃ©sentative
âŒ Grands trous temporels (ex: 30 jours sans donnÃ©es)
âŒ PrÃ©dictions basÃ©es sur des donnÃ©es sporadiques
âŒ ModÃ¨le apprend du bruit au lieu du signal
```

### AprÃ¨s: DonnÃ©es FiltrÃ©es et Continues
```
AmÃ©liorations:
âœ… Seulement les pÃ©riodes avec volume suffisant (min 5 reviews par dÃ©faut)
âœ… DÃ©tection automatique des trous temporels
âœ… SÃ©lection du segment continu le plus long
âœ… Meilleure qualitÃ© de prÃ©diction
```

---

## ğŸ”§ Nouvelle FonctionnalitÃ©: ContrÃ´le de QualitÃ©

### Interface Dashboard

```
ğŸ“Š Data Quality Controls
â”œâ”€ Min Reviews per Day: [slider 1-50, dÃ©faut 5]
â””â”€ Expected Min Data Points: ~40
```

### ParamÃ¨tre: `min_samples_per_period`

**DÃ©finition**: Nombre minimum de reviews requis par pÃ©riode temporelle (jour/semaine/mois)

**Impact**:
- **Valeur basse (1-3)**: Plus de data points, mais qualitÃ© moyenne
- **Valeur moyenne (5-10)**: Balance qualitÃ©/quantitÃ© â­ **RECOMMANDÃ‰**
- **Valeur haute (15-50)**: Excellente qualitÃ©, mais peu de data points

---

## ğŸ“ˆ Filtrage en 3 Ã‰tapes

### Ã‰tape 1: Filtrage par Volume

**Code**:
```python
ts_data = ts_data[ts_data['count'] >= min_samples_per_period]
```

**Exemple (min_samples_per_period=5)**:
```
AVANT:
Date       | y    | count
-----------|------|-------
2024-01-01 | 0.70 | 8   âœ… GardÃ©
2024-01-02 | 0.85 | 2   âŒ SupprimÃ© (count < 5)
2024-01-03 | 0.68 | 6   âœ… GardÃ©
2024-01-04 | 0.90 | 1   âŒ SupprimÃ© (count < 5)
2024-01-05 | 0.72 | 12  âœ… GardÃ©

APRÃˆS:
Date       | y    | count
-----------|------|-------
2024-01-01 | 0.70 | 8
2024-01-03 | 0.68 | 6
2024-01-05 | 0.72 | 12
```

**Pourquoi c'est important**:
- Moyenne de 2 reviews n'est pas statistiquement fiable
- Une seule review extrÃªme peut fausser toute la journÃ©e
- Volume Ã©levÃ© = confiance dans la mesure

---

### Ã‰tape 2: DÃ©tection des Trous Temporels

**Seuils de Gap Maximum**:
```python
AgrÃ©gation Daily:   max_gap = 7 jours
AgrÃ©gation Weekly:  max_gap = 4 semaines
AgrÃ©gation Monthly: max_gap = 2 mois
```

**Exemple (Daily)**:
```
Time Series:
2024-01-01 â”€â”€â”€â”€â”
2024-01-02     â”‚ Segment 1 (continu)
2024-01-03     â”‚
2024-01-04 â”€â”€â”€â”€â”˜
               â†“ GAP de 25 jours! (> 7 jours max)
2024-01-30 â”€â”€â”€â”€â”
2024-01-31     â”‚
2024-02-01     â”‚ Segment 2 (continu)
2024-02-02     â”‚
2024-02-03 â”€â”€â”€â”€â”˜

â†’ ModÃ¨le voit 2 segments sÃ©parÃ©s
```

**Pourquoi dÃ©tecter les gaps**:
- Un trou de 30 jours rompt la continuitÃ© temporelle
- ARIMA/Prophet supposent des donnÃ©es rÃ©guliÃ¨res
- Gap = perte de contexte pour les prÃ©dictions

---

### Ã‰tape 3: SÃ©lection du Segment le Plus Long

**Logique**:
```python
# Diviser Ã  chaque gap
segments = []
for gap in large_gaps:
    segment = ts_data[start:gap]
    if len(segment) >= 10:
        segments.append(segment)

# Garder le plus long
ts_data = max(segments, key=len)
```

**Exemple Visuel**:
```
Segment 1: 15 jours (Jan 1-15)
Segment 2: 45 jours (Feb 1 - Mar 15)  â† SÃ‰LECTIONNÃ‰!
Segment 3: 8 jours (Apr 1-8) - IgnorÃ© (< 10 points)

RÃ©sultat: ModÃ¨le entraÃ®nÃ© sur Segment 2 uniquement
```

**Message Dashboard**:
```
âš ï¸ Time series had gaps. Using longest continuous segment: 
   45 periods from 2024-02-01 to 2024-03-15
```

---

## ğŸ“ Exemples Concrets

### Exemple 1: Produit Nouveau avec DonnÃ©es Sporadiques

**ScÃ©nario**: Produit lancÃ© il y a 3 mois, reviews irrÃ©guliÃ¨res

**DonnÃ©es Brutes** (Daily aggregation):
```
Total: 90 jours possibles
Jours avec â‰¥1 review: 42 jours
Jours avec â‰¥5 reviews: 18 jours
```

**Avec min_samples_per_period=5**:
```
âœ… Garde seulement 18 jours avec volume suffisant
âœ… Trouve un segment continu de 12 jours (Feb 10-21)
âœ… PrÃ©dictions basÃ©es sur donnÃ©es de qualitÃ©
```

**Impact**:
- Sans filtre: 42 points bruitÃ©s
- Avec filtre: 12 points de qualitÃ© â† **Meilleur signal!**

---

### Exemple 2: Aspect Populaire avec Bonne Distribution

**ScÃ©nario**: "battery" - 500 reviews sur 60 jours

**DonnÃ©es Brutes**:
```
60 jours, chaque jour: 5-15 reviews
Moyenne: 8.3 reviews/jour
Pas de gaps
```

**Avec min_samples_per_period=5**:
```
âœ… Garde tous les 60 jours (tous â‰¥5 reviews)
âœ… Aucun gap dÃ©tectÃ©
âœ… Segment unique de 60 jours
âœ… Excellente base pour prÃ©diction!
```

**RÃ©sultat**: `60 historical data points` (optimal)

---

### Exemple 3: Aspect Rare avec DonnÃ©es DispersÃ©es

**ScÃ©nario**: "screen_protector" - 80 reviews sur 90 jours

**DonnÃ©es Brutes**:
```
Jours avec reviews: 35 jours
Distribution irrÃ©guliÃ¨re:
- Semaine 1-2: 15 reviews/jour âœ…
- Semaine 3-6: 0-2 reviews/jour âŒ
- Semaine 7-8: 12 reviews/jour âœ…
```

**Avec min_samples_per_period=5**:
```
âŒ Segment 1: 14 jours (Semaine 1-2)
âŒ Segment 2: 0 jours (Semaine 3-6, tous < 5)
âŒ Segment 3: 14 jours (Semaine 7-8)

â†’ SÃ©lectionne un des segments de 14 jours
âš ï¸ Recommandation: AgrÃ©ger en Weekly au lieu de Daily
```

---

## âš™ï¸ Comment Choisir les ParamÃ¨tres

### ParamÃ¨tre 1: `min_samples_per_period`

| Valeur | Usage | Avantages | InconvÃ©nients |
|--------|-------|-----------|---------------|
| **1-2** | Produits nouveaux, aspects rares | Maximum de data points | DonnÃ©es bruitÃ©es |
| **3-5** | Usage standard | Balance qualitÃ©/quantitÃ© | Quelques points perdus |
| **5-10** | â­ **RECOMMANDÃ‰** | Bonne qualitÃ© statistique | Moins de data points |
| **10-20** | Produits populaires | Excellente qualitÃ© | Beaucoup de points perdus |
| **>20** | Analyses spÃ©ciales | QualitÃ© maximale | TrÃ¨s peu de data points |

### ParamÃ¨tre 2: `Aggregation Frequency`

**Relation avec min_samples**:
```
Daily + min_samples=5
â†’ Besoin: 5 reviews/jour
â†’ Si produit a ~30 reviews/semaine â†’ seulement 4.3/jour
â†’ RÃ©sultat: DonnÃ©es insuffisantes âŒ

Solution: Passer Ã  Weekly
â†’ Weekly + min_samples=5
â†’ Besoin: 5 reviews/semaine
â†’ 30 reviews/semaine â†’ OK! âœ…
```

**RÃ¨gle gÃ©nÃ©rale**:
```
Daily:   Pour produits avec >50 reviews/jour
Weekly:  Pour produits avec >20 reviews/semaine (STANDARD)
Monthly: Pour produits avec <50 reviews/mois
```

---

## ğŸ” Diagnostic: Quand Ajuster

### Erreur: "Insufficient data after volume filtering"

**Cause**: Trop peu de pÃ©riodes avec le volume minimum requis

**Solutions**:
```
Option 1: â†“ RÃ©duire min_samples_per_period (5 â†’ 3)
Option 2: â†‘ Changer aggregation (Daily â†’ Weekly)
Option 3: â†‘ Augmenter date range (3 mois â†’ 6 mois)
Option 4: Choisir un aspect plus populaire
```

### Erreur: "No continuous time segment found"

**Cause**: DonnÃ©es trop fragmentÃ©es, tous les segments <10 points

**Solutions**:
```
Option 1: â†“ RÃ©duire min_samples_per_period drastiquement
Option 2: â†‘ Changer aggregation pour rÃ©duire gaps
Option 3: SÃ©lectionner un produit spÃ©cifique (pas "All")
Option 4: VÃ©rifier qualitÃ© des donnÃ©es source
```

### Warning: "Using longest continuous segment: X periods"

**Cause**: Gaps dÃ©tectÃ©s dans les donnÃ©es

**InterprÃ©tation**:
```
âœ… X â‰¥ 30: Excellent, segment suffisant
âœ… X â‰¥ 20: Bon, prÃ©dictions fiables
âš ï¸ X â‰¥ 10: Acceptable, mais court terme seulement
âŒ X < 10: Insuffisant, revoir paramÃ¨tres
```

---

## ğŸ“Š MÃ©triques de QualitÃ©

### Metric 1: Data Coverage

```python
Coverage = (periods_with_data / total_periods) Ã— 100%

Exemple:
90 jours possibles
45 jours avec â‰¥5 reviews
Coverage = 45/90 = 50%

InterprÃ©tation:
âœ… >70%: Excellente couverture
âœ… 40-70%: Bonne couverture
âš ï¸ 20-40%: Couverture moyenne
âŒ <20%: Couverture faible
```

### Metric 2: Segment Continuity

```python
Continuity = (largest_segment / total_periods) Ã— 100%

Exemple:
90 jours total
60 jours dans plus grand segment
Continuity = 60/90 = 67%

InterprÃ©tation:
âœ… >80%: TrÃ¨s continu
âœ… 50-80%: Relativement continu
âš ï¸ 30-50%: FragmentÃ©
âŒ <30%: TrÃ¨s fragmentÃ©
```

### Metric 3: Average Volume

```python
Avg Volume = total_reviews / periods_with_data

Exemple:
500 reviews
45 pÃ©riodes avec donnÃ©es
Avg = 500/45 = 11.1 reviews/pÃ©riode

InterprÃ©tation:
âœ… >15: Excellent volume
âœ… 8-15: Bon volume
âš ï¸ 5-8: Volume acceptable
âŒ <5: Volume faible
```

---

## ğŸ¯ Workflows RecommandÃ©s

### Workflow 1: Nouveau Produit

```
1. Commencer avec:
   â”œâ”€ Aggregation: Weekly
   â”œâ”€ Min samples: 3
   â””â”€ Date range: Depuis lancement

2. VÃ©rifier rÃ©sultat:
   â”œâ”€ Si â‰¥20 data points: âœ… OK
   â””â”€ Si <20 data points: Passer Ã  Monthly

3. InterprÃ©ter avec prudence:
   â””â”€ Peu d'historique = grandes incertitudes
```

### Workflow 2: Produit Ã‰tabli

```
1. Configuration standard:
   â”œâ”€ Aggregation: Daily ou Weekly
   â”œâ”€ Min samples: 5
   â””â”€ Date range: 6-12 mois

2. Optimisation:
   â”œâ”€ VÃ©rifier warning sur gaps
   â”œâ”€ Si gaps: RÃ©duire date range pour capturer pÃ©riode continue
   â””â”€ Comparer Daily vs Weekly

3. Validation:
   â””â”€ Viser â‰¥30 data points pour prÃ©dictions stables
```

### Workflow 3: Aspect Rare

```
1. Ajustements nÃ©cessaires:
   â”œâ”€ Aggregation: Weekly ou Monthly
   â”œâ”€ Min samples: 1-3 (plus permissif)
   â””â”€ ConsidÃ©rer grouper avec aspects similaires

2. Alternatives:
   â”œâ”€ SÃ©lectionner produit spÃ©cifique (pas All)
   â”œâ”€ Analyser seulement pÃ©riode rÃ©cente
   â””â”€ Utiliser Weekly obligatoirement
```

---

## ğŸ’¡ Best Practices

### âœ… Ã€ Faire

1. **Toujours vÃ©rifier le nombre de data points**
   - Minimum absolu: 10 points
   - RecommandÃ©: 30+ points
   - IdÃ©al: 60+ points

2. **Adapter l'agrÃ©gation au volume**
   - Beaucoup de reviews â†’ Daily
   - Volume moyen â†’ Weekly
   - Peu de reviews â†’ Monthly

3. **Lire les warnings**
   - "Using longest segment" â†’ Normal si gaps temporels
   - Noter la pÃ©riode utilisÃ©e pour interprÃ©tation

4. **Commencer conservateur**
   - min_samples=5 par dÃ©faut
   - Ajuster seulement si problÃ¨mes

### âŒ Ã€ Ã‰viter

1. **Ne pas forcer Daily sur aspects rares**
   - RÃ©sultat: Beaucoup de jours vides
   - Solution: Passer Ã  Weekly

2. **Ne pas mettre min_samples trop haut**
   - min_samples=20 â†’ Perd trop de donnÃ©es
   - Sauf si volume vraiment Ã©levÃ©

3. **Ne pas ignorer les erreurs**
   - "Insufficient data" = problÃ¨me rÃ©el
   - Ajuster paramÃ¨tres, pas forcer

4. **Ne pas analyser segments trop courts**
   - <10 points = prÃ©dictions non fiables
   - Mieux: Augmenter date range ou changer aspect

---

## ğŸ”¬ Validation: Comment Savoir Si C'est Bon?

### Checklist de QualitÃ©

```
âœ… Data points â‰¥ 30
âœ… Segment continu (pas de warning gap)
âœ… Average volume â‰¥ 5 reviews/pÃ©riode
âœ… Intervalles de confiance raisonnables (<0.3 de largeur)
âœ… Trend visuellement cohÃ©rent
```

### Indicateurs Visuels

**Bon forecast**:
```
- Courbe historique lisse
- Intervalle de confiance stable
- Tendance claire et progressive
```

**Mauvais forecast**:
```
- Courbe historique erratique (zigzag)
- Intervalle de confiance trÃ¨s large
- PrÃ©diction plate ou extrÃªme
```

---

**Version**: 1.0  
**DerniÃ¨re mise Ã  jour**: 21 Novembre 2025  
**Auteur**: ABSA Dashboard Team
