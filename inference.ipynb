{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee26c971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No CUDA GPU found in your device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FX506\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\spacy\\cli\\_util.py:23: DeprecationWarning: Importing 'parser.split_arg_string' is deprecated, it will only be available in 'shell_completion' in Click 9.0.\n",
      "  from click.parser import split_arg_string\n",
      "C:\\Users\\FX506\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\weasel\\util\\config.py:8: DeprecationWarning: Importing 'parser.split_arg_string' is deprecated, it will only be available in 'shell_completion' in Click 9.0.\n",
      "  from click.parser import split_arg_string\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-11-17 13:50:55] (2.4.2) PyABSA(2.4.2): If your code crashes on Colab, please use the GPU runtime. Then run \"pip install pyabsa[dev] -U\" and restart the kernel.\n",
      "Or if it does not work, you can use v1.x versions, e.g., pip install pyabsa<2.0 -U\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "WARNING: When you fails to load a checkpoint, e.g., Unexpected key(s),\n",
      "Try to downgrade transformers<=4.29.0.\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from transformers import DebertaV2TokenizerFast\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from pyabsa import AspectTermExtraction as ATEPC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c27a759",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "product_file_path = r\"full-00000-of-00001.parquet\"\n",
    "review_file_path = r\"All_Beauty.jsonl\"\n",
    "\n",
    "product_df = pd.read_parquet(os.path.join(\"data\", product_file_path))\n",
    "df = pd.read_json(os.path.join(\"data\", review_file_path), lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "705583f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of 2020 , i want the user to choose the year\n",
    "selected_year = int(input(\"Enter the year you want to filter by (default is 2020): \") or 2020)  \n",
    "df = df[df['timestamp'].dt.year == selected_year]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "434a729e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>images</th>\n",
       "      <th>asin</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>helpful_vote</th>\n",
       "      <th>verified_purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Such a lovely scent but not overpowering.</td>\n",
       "      <td>This spray is really nice. It smells really go...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B00YQ6X8EO</td>\n",
       "      <td>B00YQ6X8EO</td>\n",
       "      <td>AGKHLEW2SOWHNMFQIJGBECAF7INQ</td>\n",
       "      <td>2020-05-05 14:08:48.923</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Works great but smells a little weird.</td>\n",
       "      <td>This product does what I need it to do, I just...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B081TJ8YS3</td>\n",
       "      <td>B081TJ8YS3</td>\n",
       "      <td>AGKHLEW2SOWHNMFQIJGBECAF7INQ</td>\n",
       "      <td>2020-05-04 18:10:55.070</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Yes!</td>\n",
       "      <td>Smells good, feels great!</td>\n",
       "      <td>[]</td>\n",
       "      <td>B07PNNCSP9</td>\n",
       "      <td>B097R46CSY</td>\n",
       "      <td>AE74DYR3QUGVPZJ3P7RFWBGIX7XQ</td>\n",
       "      <td>2020-05-16 21:41:06.052</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>A+</td>\n",
       "      <td>Love it</td>\n",
       "      <td>[]</td>\n",
       "      <td>B08BZ63GMJ</td>\n",
       "      <td>B08BZ63GMJ</td>\n",
       "      <td>AFQLNQNQYFWQZPJQZS6V3NZU4QBQ</td>\n",
       "      <td>2020-12-30 10:02:43.534</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>Pretty Color</td>\n",
       "      <td>The polish was quiet thick and did not apply s...</td>\n",
       "      <td>[{'small_image_url': 'https://images-na.ssl-im...</td>\n",
       "      <td>B00R8DXL44</td>\n",
       "      <td>B00R8DXL44</td>\n",
       "      <td>AGMJ3EMDVL6OWBJF7CA5RGJLXN5A</td>\n",
       "      <td>2020-08-27 22:30:08.138</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701509</th>\n",
       "      <td>5</td>\n",
       "      <td>Lo recomiendo</td>\n",
       "      <td>Excelente resultado.</td>\n",
       "      <td>[]</td>\n",
       "      <td>B01MDTVZTZ</td>\n",
       "      <td>B01MDTVZTZ</td>\n",
       "      <td>AF4HRHKZUDYAXOU3RQN3CQZ7A35A</td>\n",
       "      <td>2020-11-28 21:15:33.807</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701511</th>\n",
       "      <td>1</td>\n",
       "      <td>Wrong product, wrong description</td>\n",
       "      <td>It is only for cleaning.  It is not for shavin...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B087FX6PPM</td>\n",
       "      <td>B087FX6PPM</td>\n",
       "      <td>AGY4XVENEBLOGFGUCFOAR4VJDE7A</td>\n",
       "      <td>2020-10-11 02:02:34.655</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701514</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth the buy !</td>\n",
       "      <td>Love !! The five packs worked with all my hair...</td>\n",
       "      <td>[{'small_image_url': 'https://images-na.ssl-im...</td>\n",
       "      <td>B07X3QMQS6</td>\n",
       "      <td>B07X3QMQS6</td>\n",
       "      <td>AFDPITZLCGMHQF7LUTDUA6EPNYXQ</td>\n",
       "      <td>2020-09-30 18:21:00.051</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701522</th>\n",
       "      <td>1</td>\n",
       "      <td>I got a completely different bottle than this.</td>\n",
       "      <td>What I got was a completely different bottle t...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B00K21WP3M</td>\n",
       "      <td>B00K21WP3M</td>\n",
       "      <td>AGZIX3V6YHAG3JCUUUWY57FBO5OA</td>\n",
       "      <td>2020-04-09 18:02:48.241</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701525</th>\n",
       "      <td>5</td>\n",
       "      <td>Great sunless tanner</td>\n",
       "      <td>Product as expected. Shipping was on time.</td>\n",
       "      <td>[]</td>\n",
       "      <td>B06ZZV9MZT</td>\n",
       "      <td>B06ZZV9MZT</td>\n",
       "      <td>AHYDCWDMMVMLBX7FY7M7JKADKRDQ</td>\n",
       "      <td>2020-05-27 02:52:54.067</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126753 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        rating                                           title  \\\n",
       "0            5       Such a lovely scent but not overpowering.   \n",
       "1            4          Works great but smells a little weird.   \n",
       "2            5                                            Yes!   \n",
       "4            5                                              A+   \n",
       "5            4                                    Pretty Color   \n",
       "...        ...                                             ...   \n",
       "701509       5                                   Lo recomiendo   \n",
       "701511       1                Wrong product, wrong description   \n",
       "701514       5                                 Worth the buy !   \n",
       "701522       1  I got a completely different bottle than this.   \n",
       "701525       5                            Great sunless tanner   \n",
       "\n",
       "                                                     text  \\\n",
       "0       This spray is really nice. It smells really go...   \n",
       "1       This product does what I need it to do, I just...   \n",
       "2                               Smells good, feels great!   \n",
       "4                                                 Love it   \n",
       "5       The polish was quiet thick and did not apply s...   \n",
       "...                                                   ...   \n",
       "701509                               Excelente resultado.   \n",
       "701511  It is only for cleaning.  It is not for shavin...   \n",
       "701514  Love !! The five packs worked with all my hair...   \n",
       "701522  What I got was a completely different bottle t...   \n",
       "701525         Product as expected. Shipping was on time.   \n",
       "\n",
       "                                                   images        asin  \\\n",
       "0                                                      []  B00YQ6X8EO   \n",
       "1                                                      []  B081TJ8YS3   \n",
       "2                                                      []  B07PNNCSP9   \n",
       "4                                                      []  B08BZ63GMJ   \n",
       "5       [{'small_image_url': 'https://images-na.ssl-im...  B00R8DXL44   \n",
       "...                                                   ...         ...   \n",
       "701509                                                 []  B01MDTVZTZ   \n",
       "701511                                                 []  B087FX6PPM   \n",
       "701514  [{'small_image_url': 'https://images-na.ssl-im...  B07X3QMQS6   \n",
       "701522                                                 []  B00K21WP3M   \n",
       "701525                                                 []  B06ZZV9MZT   \n",
       "\n",
       "       parent_asin                       user_id               timestamp  \\\n",
       "0       B00YQ6X8EO  AGKHLEW2SOWHNMFQIJGBECAF7INQ 2020-05-05 14:08:48.923   \n",
       "1       B081TJ8YS3  AGKHLEW2SOWHNMFQIJGBECAF7INQ 2020-05-04 18:10:55.070   \n",
       "2       B097R46CSY  AE74DYR3QUGVPZJ3P7RFWBGIX7XQ 2020-05-16 21:41:06.052   \n",
       "4       B08BZ63GMJ  AFQLNQNQYFWQZPJQZS6V3NZU4QBQ 2020-12-30 10:02:43.534   \n",
       "5       B00R8DXL44  AGMJ3EMDVL6OWBJF7CA5RGJLXN5A 2020-08-27 22:30:08.138   \n",
       "...            ...                           ...                     ...   \n",
       "701509  B01MDTVZTZ  AF4HRHKZUDYAXOU3RQN3CQZ7A35A 2020-11-28 21:15:33.807   \n",
       "701511  B087FX6PPM  AGY4XVENEBLOGFGUCFOAR4VJDE7A 2020-10-11 02:02:34.655   \n",
       "701514  B07X3QMQS6  AFDPITZLCGMHQF7LUTDUA6EPNYXQ 2020-09-30 18:21:00.051   \n",
       "701522  B00K21WP3M  AGZIX3V6YHAG3JCUUUWY57FBO5OA 2020-04-09 18:02:48.241   \n",
       "701525  B06ZZV9MZT  AHYDCWDMMVMLBX7FY7M7JKADKRDQ 2020-05-27 02:52:54.067   \n",
       "\n",
       "        helpful_vote  verified_purchase  \n",
       "0                  0               True  \n",
       "1                  1               True  \n",
       "2                  2               True  \n",
       "4                  0               True  \n",
       "5                  0               True  \n",
       "...              ...                ...  \n",
       "701509             0               True  \n",
       "701511             0               True  \n",
       "701514             0               True  \n",
       "701522             0               True  \n",
       "701525             0               True  \n",
       "\n",
       "[126753 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c10d790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ydata_profiling import ProfileReport\n",
    "\n",
    "# ProfileReport(df, title='Reviews Dataset Report', minimal=True, progress_bar=False, samples=None, correlations=None, interactions=None, explorative=True, notebook={'iframe':{'height': '600px'}}, html={'style':{'primary_color': '#583101'}}, missing_diagrams={'heatmap': False, 'dendrogram': False}).to_notebook_iframe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2392561a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BEAUTY PRODUCT ANALYSIS - MONTH SELECTOR\n",
      "============================================================\n",
      "Invalid input. Please enter a number.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# MONTH SELECTION\n",
    "# ============================================================================\n",
    "print(\"=\"*60)\n",
    "print(\"BEAUTY PRODUCT ANALYSIS - MONTH SELECTOR\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        month_input = input(\"\\nEnter the month number (1-12): \").strip()\n",
    "        selected_month = int(month_input)\n",
    "        if 1 <= selected_month <= 12:\n",
    "            break\n",
    "        else:\n",
    "            print(\"Please enter a number between 1 and 12\")\n",
    "    except ValueError:\n",
    "        print(\"Invalid input. Please enter a number.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34cffda7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rating', 'title', 'text', 'images', 'asin', 'parent_asin', 'user_id',\n",
       "       'timestamp', 'helpful_vote', 'verified_purchase'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f346cfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop  duplicates \n",
    "df = df.drop(columns=['images'])\n",
    "df = df.drop_duplicates ( keep=\"first\")\n",
    "# keep verified reviews only\n",
    "df = df[df['verified_purchase'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4364cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ============================================================================\n",
    "# SETUP AND PATCHING\n",
    "# ============================================================================\n",
    "# Apply the nuclear patch for DeBERTa tokenizer\n",
    "original_getattr = DebertaV2TokenizerFast.__getattr__ if hasattr(DebertaV2TokenizerFast, '__getattr__') else None\n",
    "\n",
    "def custom_getattr(self, name):\n",
    "    defaults = {\n",
    "        'bos_token': None,\n",
    "        'eos_token': None,\n",
    "        'split_special_tokens': False,\n",
    "        'cls_token': '[CLS]',\n",
    "        'sep_token': '[SEP]',\n",
    "        'unk_token': '[UNK]',\n",
    "        'pad_token': '[PAD]',\n",
    "        'mask_token': '[MASK]',\n",
    "    }\n",
    "    \n",
    "    if name.endswith('_id') and name[:-3] in defaults:\n",
    "        token_name = name[:-3]\n",
    "        token = defaults.get(token_name)\n",
    "        if token and hasattr(self, 'convert_tokens_to_ids'):\n",
    "            try:\n",
    "                return self.convert_tokens_to_ids(token)\n",
    "            except:\n",
    "                return 0\n",
    "        return 0\n",
    "    \n",
    "    if name in defaults:\n",
    "        private_name = f'_{name}'\n",
    "        if hasattr(self, private_name):\n",
    "            return getattr(self, private_name)\n",
    "        return defaults[name]\n",
    "    \n",
    "    if original_getattr:\n",
    "        return original_getattr(self, name)\n",
    "    \n",
    "    raise AttributeError(f\"'{type(self).__name__}' object has no attribute '{name}'\")\n",
    "\n",
    "DebertaV2TokenizerFast.__getattr__ = custom_getattr\n",
    "\n",
    "# Initialize the aspect extractor\n",
    "print(\"\\nLoading ABSA model...\")\n",
    "checkpoint_path = os.path.join(\n",
    "    'checkpoints', \n",
    "    'ATEPC_ENGLISH_CHECKPOINT', \n",
    "    'fast_lcf_atepc_English_cdw_apcacc_82.36_apcf1_81.89_atef1_75.43'\n",
    ")\n",
    "aspect_extractor = ATEPC.AspectExtractor(checkpoint_path, auto_device=True)\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD AND FILTER DATA\n",
    "# ============================================================================\n",
    "print(\"\\nLoading dataset...\")\n",
    "if df['timestamp'].dtype == 'O' or not pd.api.types.is_datetime64_any_dtype(df['timestamp']):\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
    "\n",
    "df_filtered = df[df['timestamp'].dt.month == selected_month].copy()\n",
    "print(f'Filtered rows for month {selected_month}: {len(df_filtered)}')\n",
    "\n",
    "# ============================================================================\n",
    "# CSV SETUP FOR RESUMABLE PROCESSING\n",
    "# ============================================================================\n",
    "output_csv = os.path.join(\"absa_output\" ,\n",
    "                            f\"{datetime(1900, selected_month, 1).strftime('%b')}\"\n",
    "                            f\"{str(selected_year)[-2:]}\", \n",
    "                            f\"beauty_absa_results.csv\")\n",
    "processed_ids = set()\n",
    "\n",
    "# Check if CSV already exists and load processed IDs\n",
    "if os.path.exists(output_csv):\n",
    "    print(f\"\\nFound existing results file: {output_csv}\")\n",
    "    existing_df = pd.read_csv(output_csv, dtype={'review_id': str})\n",
    "    processed_ids = set(existing_df['review_id'].astype(str).unique())\n",
    "    print(f\"Resuming from {len(processed_ids)} already processed reviews\")\n",
    "    start_row = len(processed_ids)\n",
    "else:\n",
    "    print(f\"\\nCreating new results file: {output_csv}\")\n",
    "    start_row = 0\n",
    "\n",
    "# ============================================================================\n",
    "# PROCESS REVIEWS WITH ABSA\n",
    "# ============================================================================\n",
    "print(f\"\\nProcessing reviews with ABSA...\\n\")\n",
    "results = []\n",
    "total_to_process = len(df_filtered)\n",
    "\n",
    "for idx, (row_idx, row) in enumerate(df_filtered.iterrows()):\n",
    "    review_id = str(row_idx)\n",
    "    \n",
    "    # Skip if already processed\n",
    "    if review_id in processed_ids:\n",
    "        continue\n",
    "\n",
    "    review_text = row['title'] + \" \" + row['text'] if not pd.isna(row['title']) and not pd.isna(row['text']) else row['text'] if not pd.isna(row['text']) else row['title'] if not pd.isna(row['title']) else \"\"\n",
    "    \n",
    "    # Skip empty reviews    \n",
    "    if not review_text.strip():\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        prediction = aspect_extractor.predict(\n",
    "            review_text,\n",
    "            save_result=False,\n",
    "            print_result=False,\n",
    "            ignore_error=True\n",
    "        )\n",
    "        \n",
    "        aspects = []\n",
    "        if prediction and isinstance(prediction, dict):\n",
    "            if 'aspect' in prediction and 'sentiment' in prediction:\n",
    "                for i, aspect in enumerate(prediction['aspect']):\n",
    "                    sentiment = prediction['sentiment'][i] if i < len(prediction['sentiment']) else 'Neutral'\n",
    "                    confidence = prediction.get('confidence', [1.0])[i] if i < len(prediction.get('confidence', [1.0])) else 1.0\n",
    "                    aspects.append({\n",
    "                        'term': aspect,\n",
    "                        'sentiment': sentiment,\n",
    "                        'confidence': confidence\n",
    "                    })\n",
    "        \n",
    "        result_dict = {\n",
    "            'review_id': review_id,\n",
    "            'rating': row.get('rating', 0),\n",
    "            'text': review_text[:500],  # Truncate text for CSV storage\n",
    "            'timestamp': row.get('timestamp', ''),\n",
    "            'user_id': row.get('user_id', ''),\n",
    "            'parent_asin': row.get('parent_asin', ''),\n",
    "            'aspects_json': json.dumps(aspects),\n",
    "        }\n",
    "        \n",
    "        results.append(result_dict)\n",
    "        \n",
    "        if len(results) % 10 == 0:\n",
    "            print(f\"Progress: {start_row + len(results)}/{total_to_process} reviews\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing review {review_id}: {str(e)[:50]}\")\n",
    "        result_dict = {\n",
    "            'review_id': review_id,\n",
    "            'rating': row.get('rating', 0),\n",
    "            'text': review_text[:500],\n",
    "            'timestamp': row.get('timestamp', ''),\n",
    "            'user_id': row.get('user_id', ''),\n",
    "            'parent_asin': row.get('parent_asin', ''),\n",
    "            'aspects_json': '[]',\n",
    "        }\n",
    "        results.append(result_dict)\n",
    "\n",
    "# ============================================================================\n",
    "# SAVE TO CSV (APPEND MODE)\n",
    "# ============================================================================\n",
    "if results:\n",
    "    results_df = pd.DataFrame(results)\n",
    "    # create output directory if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(output_csv), exist_ok=True)\n",
    "    if os.path.exists(output_csv):\n",
    "        results_df.to_csv(output_csv, mode='a', header=False, index=False, encoding='utf-8')\n",
    "    else:\n",
    "        results_df.to_csv(output_csv, index=False, encoding='utf-8')\n",
    "    \n",
    "    print(f\"\\n✓ Saved {len(results)} new reviews to {output_csv}\")\n",
    "else:\n",
    "    print(\"\\nNo new reviews to process\")\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD ALL RESULTS FOR ANALYSIS\n",
    "# ============================================================================\n",
    "all_results_df = pd.read_csv(output_csv, dtype={'review_id': str})\n",
    "print(f\"Total reviews in file: {len(all_results_df)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# GENERATE ANALYSIS SUMMARY\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BEAUTY PRODUCT ANALYSIS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "all_aspects = {}\n",
    "sentiment_counts = {'Positive': 0, 'Negative': 0, 'Neutral': 0}\n",
    "\n",
    "for _, row in all_results_df.iterrows():\n",
    "    try:\n",
    "        aspects = json.loads(row['aspects_json'])\n",
    "        for aspect in aspects:\n",
    "            term = aspect['term']\n",
    "            sentiment = aspect['sentiment']\n",
    "            \n",
    "            if term not in all_aspects:\n",
    "                all_aspects[term] = {'Positive': 0, 'Negative': 0, 'Neutral': 0, 'total': 0}\n",
    "            \n",
    "            all_aspects[term][sentiment] += 1\n",
    "            all_aspects[term]['total'] += 1\n",
    "            sentiment_counts[sentiment] += 1\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "print(f\"\\nTop 10 Most Mentioned Beauty Aspects:\")\n",
    "if all_aspects:\n",
    "    sorted_aspects = sorted(all_aspects.items(), key=lambda x: x[1]['total'], reverse=True)[:10]\n",
    "    for term, counts in sorted_aspects:\n",
    "        if counts['total'] > 0:\n",
    "            sentiment_score = (counts['Positive'] - counts['Negative']) / counts['total']\n",
    "            print(f\"  {term}: {counts['total']} mentions (Score: {sentiment_score:.2f})\")\n",
    "            print(f\"    Positive: {counts['Positive']}, Negative: {counts['Negative']}, Neutral: {counts['Neutral']}\")\n",
    "else:\n",
    "    print(\"  No aspects detected in the processed reviews.\")\n",
    "\n",
    "print(f\"\\nOverall Beauty Product Sentiment Distribution:\")\n",
    "print(f\"  Positive: {sentiment_counts['Positive']}\")\n",
    "print(f\"  Negative: {sentiment_counts['Negative']}\")\n",
    "print(f\"  Neutral: {sentiment_counts['Neutral']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"✓ Analysis complete! Results saved to {output_csv}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b8b5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== ADVANCED PREPROCESSING =====================\n",
    "import re\n",
    "import unicodedata\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "STOP_WORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return ''\n",
    "    # Unicode normalization\n",
    "    text = unicodedata.normalize('NFKC', text)\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
    "    # Remove special characters\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    # Remove excessive whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove stopwords\n",
    "    tokens = text.split()\n",
    "    tokens = [t for t in tokens if t not in STOP_WORDS]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Impute missing ratings with product-level median\n",
    "if 'rating' in df.columns:\n",
    "    df['rating'] = df.groupby('parent_asin')['rating'].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "# Remove reviews with missing text or timestamp\n",
    "if 'text' in df.columns and 'timestamp' in df.columns:\n",
    "    df = df[df['text'].notna() & df['timestamp'].notna()]\n",
    "\n",
    "# Remove exact duplicates (by review_id and text hash)\n",
    "df['text_hash'] = df['text'].apply(lambda x: hash(x))\n",
    "df = df.drop_duplicates(subset=['review_id', 'text_hash'], keep='first')\n",
    "del df['text_hash']\n",
    "\n",
    "# Quality filtering: exclude suspicious reviews\n",
    "# (abnormal length or strong rating–text misalignment)\n",
    "def is_suspicious(row):\n",
    "    text_len = len(row['text']) if isinstance(row['text'], str) else 0\n",
    "    if text_len < 10 or text_len > 2000:\n",
    "        return True\n",
    "    if 'rating' in row and row['rating'] in [1, 5]:\n",
    "        if 'great' in row['text'].lower() and row['rating'] == 1:\n",
    "            return True\n",
    "        if 'terrible' in row['text'].lower() and row['rating'] == 5:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "df = df[~df.apply(is_suspicious, axis=1)]\n",
    "\n",
    "# Apply text cleaning to all review texts\n",
    "if 'text' in df.columns:\n",
    "    df['text'] = df['text'].apply(clean_text)\n",
    "\n",
    "print('✓ Advanced preprocessing complete.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
