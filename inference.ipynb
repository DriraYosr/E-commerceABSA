{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee26c971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No CUDA GPU found in your device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FX506\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\spacy\\cli\\_util.py:23: DeprecationWarning: Importing 'parser.split_arg_string' is deprecated, it will only be available in 'shell_completion' in Click 9.0.\n",
      "  from click.parser import split_arg_string\n",
      "C:\\Users\\FX506\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\weasel\\util\\config.py:8: DeprecationWarning: Importing 'parser.split_arg_string' is deprecated, it will only be available in 'shell_completion' in Click 9.0.\n",
      "  from click.parser import split_arg_string\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from transformers import DebertaV2TokenizerFast\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from pyabsa import AspectTermExtraction as ATEPC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c27a759",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "product_file_path = r\"full-00000-of-00001.parquet\"\n",
    "review_file_path = r\"All_Beauty.jsonl\"\n",
    "\n",
    "product_df = pd.read_parquet(os.path.join(\"data\", product_file_path))\n",
    "df = pd.read_json(os.path.join(\"data\", review_file_path), lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "705583f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of 2020 , i want the user to choose the year\n",
    "selected_year = int(input(\"Enter the year you want to filter by (default is 2020): \") or 2020)  \n",
    "df = df[df['timestamp'].dt.year == selected_year]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "434a729e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>images</th>\n",
       "      <th>asin</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>helpful_vote</th>\n",
       "      <th>verified_purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Such a lovely scent but not overpowering.</td>\n",
       "      <td>This spray is really nice. It smells really go...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B00YQ6X8EO</td>\n",
       "      <td>B00YQ6X8EO</td>\n",
       "      <td>AGKHLEW2SOWHNMFQIJGBECAF7INQ</td>\n",
       "      <td>2020-05-05 14:08:48.923</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Works great but smells a little weird.</td>\n",
       "      <td>This product does what I need it to do, I just...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B081TJ8YS3</td>\n",
       "      <td>B081TJ8YS3</td>\n",
       "      <td>AGKHLEW2SOWHNMFQIJGBECAF7INQ</td>\n",
       "      <td>2020-05-04 18:10:55.070</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Yes!</td>\n",
       "      <td>Smells good, feels great!</td>\n",
       "      <td>[]</td>\n",
       "      <td>B07PNNCSP9</td>\n",
       "      <td>B097R46CSY</td>\n",
       "      <td>AE74DYR3QUGVPZJ3P7RFWBGIX7XQ</td>\n",
       "      <td>2020-05-16 21:41:06.052</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>A+</td>\n",
       "      <td>Love it</td>\n",
       "      <td>[]</td>\n",
       "      <td>B08BZ63GMJ</td>\n",
       "      <td>B08BZ63GMJ</td>\n",
       "      <td>AFQLNQNQYFWQZPJQZS6V3NZU4QBQ</td>\n",
       "      <td>2020-12-30 10:02:43.534</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>Pretty Color</td>\n",
       "      <td>The polish was quiet thick and did not apply s...</td>\n",
       "      <td>[{'small_image_url': 'https://images-na.ssl-im...</td>\n",
       "      <td>B00R8DXL44</td>\n",
       "      <td>B00R8DXL44</td>\n",
       "      <td>AGMJ3EMDVL6OWBJF7CA5RGJLXN5A</td>\n",
       "      <td>2020-08-27 22:30:08.138</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701509</th>\n",
       "      <td>5</td>\n",
       "      <td>Lo recomiendo</td>\n",
       "      <td>Excelente resultado.</td>\n",
       "      <td>[]</td>\n",
       "      <td>B01MDTVZTZ</td>\n",
       "      <td>B01MDTVZTZ</td>\n",
       "      <td>AF4HRHKZUDYAXOU3RQN3CQZ7A35A</td>\n",
       "      <td>2020-11-28 21:15:33.807</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701511</th>\n",
       "      <td>1</td>\n",
       "      <td>Wrong product, wrong description</td>\n",
       "      <td>It is only for cleaning.  It is not for shavin...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B087FX6PPM</td>\n",
       "      <td>B087FX6PPM</td>\n",
       "      <td>AGY4XVENEBLOGFGUCFOAR4VJDE7A</td>\n",
       "      <td>2020-10-11 02:02:34.655</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701514</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth the buy !</td>\n",
       "      <td>Love !! The five packs worked with all my hair...</td>\n",
       "      <td>[{'small_image_url': 'https://images-na.ssl-im...</td>\n",
       "      <td>B07X3QMQS6</td>\n",
       "      <td>B07X3QMQS6</td>\n",
       "      <td>AFDPITZLCGMHQF7LUTDUA6EPNYXQ</td>\n",
       "      <td>2020-09-30 18:21:00.051</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701522</th>\n",
       "      <td>1</td>\n",
       "      <td>I got a completely different bottle than this.</td>\n",
       "      <td>What I got was a completely different bottle t...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B00K21WP3M</td>\n",
       "      <td>B00K21WP3M</td>\n",
       "      <td>AGZIX3V6YHAG3JCUUUWY57FBO5OA</td>\n",
       "      <td>2020-04-09 18:02:48.241</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701525</th>\n",
       "      <td>5</td>\n",
       "      <td>Great sunless tanner</td>\n",
       "      <td>Product as expected. Shipping was on time.</td>\n",
       "      <td>[]</td>\n",
       "      <td>B06ZZV9MZT</td>\n",
       "      <td>B06ZZV9MZT</td>\n",
       "      <td>AHYDCWDMMVMLBX7FY7M7JKADKRDQ</td>\n",
       "      <td>2020-05-27 02:52:54.067</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126753 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        rating                                           title  \\\n",
       "0            5       Such a lovely scent but not overpowering.   \n",
       "1            4          Works great but smells a little weird.   \n",
       "2            5                                            Yes!   \n",
       "4            5                                              A+   \n",
       "5            4                                    Pretty Color   \n",
       "...        ...                                             ...   \n",
       "701509       5                                   Lo recomiendo   \n",
       "701511       1                Wrong product, wrong description   \n",
       "701514       5                                 Worth the buy !   \n",
       "701522       1  I got a completely different bottle than this.   \n",
       "701525       5                            Great sunless tanner   \n",
       "\n",
       "                                                     text  \\\n",
       "0       This spray is really nice. It smells really go...   \n",
       "1       This product does what I need it to do, I just...   \n",
       "2                               Smells good, feels great!   \n",
       "4                                                 Love it   \n",
       "5       The polish was quiet thick and did not apply s...   \n",
       "...                                                   ...   \n",
       "701509                               Excelente resultado.   \n",
       "701511  It is only for cleaning.  It is not for shavin...   \n",
       "701514  Love !! The five packs worked with all my hair...   \n",
       "701522  What I got was a completely different bottle t...   \n",
       "701525         Product as expected. Shipping was on time.   \n",
       "\n",
       "                                                   images        asin  \\\n",
       "0                                                      []  B00YQ6X8EO   \n",
       "1                                                      []  B081TJ8YS3   \n",
       "2                                                      []  B07PNNCSP9   \n",
       "4                                                      []  B08BZ63GMJ   \n",
       "5       [{'small_image_url': 'https://images-na.ssl-im...  B00R8DXL44   \n",
       "...                                                   ...         ...   \n",
       "701509                                                 []  B01MDTVZTZ   \n",
       "701511                                                 []  B087FX6PPM   \n",
       "701514  [{'small_image_url': 'https://images-na.ssl-im...  B07X3QMQS6   \n",
       "701522                                                 []  B00K21WP3M   \n",
       "701525                                                 []  B06ZZV9MZT   \n",
       "\n",
       "       parent_asin                       user_id               timestamp  \\\n",
       "0       B00YQ6X8EO  AGKHLEW2SOWHNMFQIJGBECAF7INQ 2020-05-05 14:08:48.923   \n",
       "1       B081TJ8YS3  AGKHLEW2SOWHNMFQIJGBECAF7INQ 2020-05-04 18:10:55.070   \n",
       "2       B097R46CSY  AE74DYR3QUGVPZJ3P7RFWBGIX7XQ 2020-05-16 21:41:06.052   \n",
       "4       B08BZ63GMJ  AFQLNQNQYFWQZPJQZS6V3NZU4QBQ 2020-12-30 10:02:43.534   \n",
       "5       B00R8DXL44  AGMJ3EMDVL6OWBJF7CA5RGJLXN5A 2020-08-27 22:30:08.138   \n",
       "...            ...                           ...                     ...   \n",
       "701509  B01MDTVZTZ  AF4HRHKZUDYAXOU3RQN3CQZ7A35A 2020-11-28 21:15:33.807   \n",
       "701511  B087FX6PPM  AGY4XVENEBLOGFGUCFOAR4VJDE7A 2020-10-11 02:02:34.655   \n",
       "701514  B07X3QMQS6  AFDPITZLCGMHQF7LUTDUA6EPNYXQ 2020-09-30 18:21:00.051   \n",
       "701522  B00K21WP3M  AGZIX3V6YHAG3JCUUUWY57FBO5OA 2020-04-09 18:02:48.241   \n",
       "701525  B06ZZV9MZT  AHYDCWDMMVMLBX7FY7M7JKADKRDQ 2020-05-27 02:52:54.067   \n",
       "\n",
       "        helpful_vote  verified_purchase  \n",
       "0                  0               True  \n",
       "1                  1               True  \n",
       "2                  2               True  \n",
       "4                  0               True  \n",
       "5                  0               True  \n",
       "...              ...                ...  \n",
       "701509             0               True  \n",
       "701511             0               True  \n",
       "701514             0               True  \n",
       "701522             0               True  \n",
       "701525             0               True  \n",
       "\n",
       "[126753 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c10d790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ydata_profiling import ProfileReport\n",
    "\n",
    "# ProfileReport(df, title='Reviews Dataset Report', minimal=True, progress_bar=False, samples=None, correlations=None, interactions=None, explorative=True, notebook={'iframe':{'height': '600px'}}, html={'style':{'primary_color': '#583101'}}, missing_diagrams={'heatmap': False, 'dendrogram': False}).to_notebook_iframe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2392561a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BEAUTY PRODUCT ANALYSIS - MONTH SELECTOR\n",
      "============================================================\n",
      "Invalid input. Please enter a number.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# MONTH SELECTION\n",
    "# ============================================================================\n",
    "print(\"=\"*60)\n",
    "print(\"BEAUTY PRODUCT ANALYSIS - MONTH SELECTOR\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        month_input = input(\"\\nEnter the month number (1-12): \").strip()\n",
    "        selected_month = int(month_input)\n",
    "        if 1 <= selected_month <= 12:\n",
    "            break\n",
    "        else:\n",
    "            print(\"Please enter a number between 1 and 12\")\n",
    "    except ValueError:\n",
    "        print(\"Invalid input. Please enter a number.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34cffda7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rating', 'title', 'text', 'images', 'asin', 'parent_asin', 'user_id',\n",
       "       'timestamp', 'helpful_vote', 'verified_purchase'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f346cfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop  duplicates \n",
    "df = df.drop(columns=['images'])\n",
    "df = df.drop_duplicates ( keep=\"first\")\n",
    "# keep verified reviews only\n",
    "df = df[df['verified_purchase'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4364cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading ABSA model...\n",
      "[2025-10-21 09:58:43] (2.4.3) Load aspect extractor from checkpoints\\ATEPC_ENGLISH_CHECKPOINT\\fast_lcf_atepc_English_cdw_apcacc_82.36_apcf1_81.89_atef1_75.43\n",
      "[2025-10-21 09:58:43] (2.4.3) config: checkpoints\\ATEPC_ENGLISH_CHECKPOINT\\fast_lcf_atepc_English_cdw_apcacc_82.36_apcf1_81.89_atef1_75.43\\fast_lcf_atepc.config\n",
      "[2025-10-21 09:58:43] (2.4.3) state_dict: checkpoints\\ATEPC_ENGLISH_CHECKPOINT\\fast_lcf_atepc_English_cdw_apcacc_82.36_apcf1_81.89_atef1_75.43\\fast_lcf_atepc.state_dict\n",
      "[2025-10-21 09:58:43] (2.4.3) model: None\n",
      "[2025-10-21 09:58:43] (2.4.3) tokenizer: checkpoints\\ATEPC_ENGLISH_CHECKPOINT\\fast_lcf_atepc_English_cdw_apcacc_82.36_apcf1_81.89_atef1_75.43\\fast_lcf_atepc.tokenizer\n",
      "[2025-10-21 09:58:43] (2.4.3) Set Model Device: cpu\n",
      "[2025-10-21 09:58:43] (2.4.3) Device Name: Unknown\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FX506\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\huggingface_hub\\file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.classifier.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "C:\\Users\\FX506\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\convert_slow_tokenizer.py:454: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n",
      "\n",
      "Loading dataset...\n",
      "Filtered rows for month 11: 9083\n",
      "\n",
      "Creating new results file: absa_output\\Nov20\\beauty_absa_results.csv\n",
      "\n",
      "Processing reviews with ABSA...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FX506\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\FX506\\Desktop\\Yosr_in_Copenhaguen_25-26\\project\\PyABSA\\pyabsa\\tasks\\AspectTermExtraction\\prediction\\aspect_extractor.py:649: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:256.)\n",
      "  lcf_cdm_vec = torch.tensor(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 10/9083 reviews\n",
      "Progress: 20/9083 reviews\n",
      "Progress: 30/9083 reviews\n",
      "Progress: 40/9083 reviews\n",
      "Progress: 50/9083 reviews\n",
      "Progress: 60/9083 reviews\n",
      "Progress: 70/9083 reviews\n",
      "Progress: 80/9083 reviews\n",
      "Progress: 90/9083 reviews\n",
      "Progress: 100/9083 reviews\n",
      "Progress: 110/9083 reviews\n",
      "Progress: 120/9083 reviews\n",
      "Progress: 130/9083 reviews\n",
      "Progress: 140/9083 reviews\n",
      "Progress: 150/9083 reviews\n",
      "Progress: 160/9083 reviews\n",
      "Progress: 170/9083 reviews\n",
      "Progress: 180/9083 reviews\n",
      "Progress: 190/9083 reviews\n",
      "Progress: 200/9083 reviews\n",
      "Progress: 210/9083 reviews\n",
      "Progress: 220/9083 reviews\n",
      "Progress: 230/9083 reviews\n",
      "Progress: 240/9083 reviews\n",
      "Progress: 250/9083 reviews\n",
      "Progress: 260/9083 reviews\n",
      "Progress: 270/9083 reviews\n",
      "Progress: 280/9083 reviews\n",
      "Progress: 290/9083 reviews\n",
      "Progress: 300/9083 reviews\n",
      "Progress: 310/9083 reviews\n",
      "Progress: 320/9083 reviews\n",
      "Progress: 330/9083 reviews\n",
      "Progress: 340/9083 reviews\n",
      "Progress: 350/9083 reviews\n",
      "Progress: 360/9083 reviews\n",
      "Progress: 370/9083 reviews\n",
      "Progress: 380/9083 reviews\n",
      "Progress: 390/9083 reviews\n",
      "Progress: 400/9083 reviews\n",
      "Progress: 410/9083 reviews\n",
      "Progress: 420/9083 reviews\n",
      "Progress: 430/9083 reviews\n",
      "Progress: 440/9083 reviews\n",
      "Progress: 450/9083 reviews\n",
      "Progress: 460/9083 reviews\n",
      "Progress: 470/9083 reviews\n",
      "Progress: 480/9083 reviews\n",
      "Progress: 490/9083 reviews\n",
      "Progress: 500/9083 reviews\n",
      "Progress: 510/9083 reviews\n",
      "Progress: 520/9083 reviews\n",
      "Progress: 530/9083 reviews\n",
      "Progress: 540/9083 reviews\n",
      "Progress: 550/9083 reviews\n",
      "Progress: 560/9083 reviews\n",
      "Progress: 570/9083 reviews\n",
      "Progress: 580/9083 reviews\n",
      "Progress: 590/9083 reviews\n",
      "Progress: 600/9083 reviews\n",
      "Progress: 610/9083 reviews\n",
      "Progress: 620/9083 reviews\n",
      "Progress: 630/9083 reviews\n",
      "Progress: 640/9083 reviews\n",
      "Progress: 650/9083 reviews\n",
      "Progress: 660/9083 reviews\n",
      "Progress: 670/9083 reviews\n",
      "Progress: 680/9083 reviews\n",
      "Progress: 690/9083 reviews\n",
      "Progress: 700/9083 reviews\n",
      "Progress: 710/9083 reviews\n",
      "Progress: 720/9083 reviews\n",
      "Progress: 730/9083 reviews\n",
      "Progress: 740/9083 reviews\n",
      "Progress: 750/9083 reviews\n",
      "Progress: 760/9083 reviews\n",
      "Progress: 770/9083 reviews\n",
      "Progress: 780/9083 reviews\n",
      "Progress: 790/9083 reviews\n",
      "Progress: 800/9083 reviews\n",
      "Progress: 810/9083 reviews\n",
      "Progress: 820/9083 reviews\n",
      "Progress: 830/9083 reviews\n",
      "Progress: 840/9083 reviews\n",
      "Progress: 850/9083 reviews\n",
      "Progress: 860/9083 reviews\n",
      "Progress: 870/9083 reviews\n",
      "Progress: 880/9083 reviews\n",
      "Progress: 890/9083 reviews\n",
      "Progress: 900/9083 reviews\n",
      "Progress: 910/9083 reviews\n",
      "Progress: 920/9083 reviews\n",
      "Progress: 930/9083 reviews\n",
      "Progress: 940/9083 reviews\n",
      "Progress: 950/9083 reviews\n",
      "Progress: 960/9083 reviews\n",
      "Progress: 970/9083 reviews\n",
      "Progress: 980/9083 reviews\n",
      "Progress: 990/9083 reviews\n",
      "Progress: 1000/9083 reviews\n",
      "Progress: 1010/9083 reviews\n",
      "Progress: 1020/9083 reviews\n",
      "Progress: 1030/9083 reviews\n",
      "Progress: 1040/9083 reviews\n",
      "Progress: 1050/9083 reviews\n",
      "Progress: 1060/9083 reviews\n",
      "Progress: 1070/9083 reviews\n",
      "Progress: 1080/9083 reviews\n",
      "Progress: 1090/9083 reviews\n",
      "Progress: 1100/9083 reviews\n",
      "Progress: 1110/9083 reviews\n",
      "Progress: 1120/9083 reviews\n",
      "Progress: 1130/9083 reviews\n",
      "Progress: 1140/9083 reviews\n",
      "Progress: 1150/9083 reviews\n",
      "Progress: 1160/9083 reviews\n",
      "Progress: 1170/9083 reviews\n",
      "Progress: 1180/9083 reviews\n",
      "Progress: 1190/9083 reviews\n",
      "Progress: 1200/9083 reviews\n",
      "Progress: 1210/9083 reviews\n",
      "Progress: 1220/9083 reviews\n",
      "Progress: 1230/9083 reviews\n",
      "Progress: 1240/9083 reviews\n",
      "Progress: 1250/9083 reviews\n",
      "Progress: 1260/9083 reviews\n",
      "Progress: 1270/9083 reviews\n",
      "Progress: 1280/9083 reviews\n",
      "Progress: 1290/9083 reviews\n",
      "Progress: 1300/9083 reviews\n",
      "Progress: 1310/9083 reviews\n",
      "Progress: 1320/9083 reviews\n",
      "Progress: 1330/9083 reviews\n",
      "Progress: 1340/9083 reviews\n",
      "Progress: 1350/9083 reviews\n",
      "Progress: 1360/9083 reviews\n",
      "Progress: 1370/9083 reviews\n",
      "Progress: 1380/9083 reviews\n",
      "Progress: 1390/9083 reviews\n",
      "Progress: 1400/9083 reviews\n",
      "Progress: 1410/9083 reviews\n",
      "Progress: 1420/9083 reviews\n",
      "Progress: 1430/9083 reviews\n",
      "Progress: 1440/9083 reviews\n",
      "Progress: 1450/9083 reviews\n",
      "Progress: 1460/9083 reviews\n",
      "Progress: 1470/9083 reviews\n",
      "Progress: 1480/9083 reviews\n",
      "Progress: 1490/9083 reviews\n",
      "Progress: 1500/9083 reviews\n",
      "Progress: 1510/9083 reviews\n",
      "Progress: 1520/9083 reviews\n",
      "Progress: 1530/9083 reviews\n",
      "Progress: 1540/9083 reviews\n",
      "Progress: 1550/9083 reviews\n",
      "Progress: 1560/9083 reviews\n",
      "Progress: 1570/9083 reviews\n",
      "Progress: 1580/9083 reviews\n",
      "Progress: 1590/9083 reviews\n",
      "Progress: 1600/9083 reviews\n",
      "Progress: 1610/9083 reviews\n",
      "Progress: 1620/9083 reviews\n",
      "Progress: 1630/9083 reviews\n",
      "Progress: 1640/9083 reviews\n",
      "Progress: 1650/9083 reviews\n",
      "Progress: 1660/9083 reviews\n",
      "Progress: 1670/9083 reviews\n",
      "Progress: 1680/9083 reviews\n",
      "Progress: 1690/9083 reviews\n",
      "Progress: 1700/9083 reviews\n",
      "Progress: 1710/9083 reviews\n",
      "Progress: 1720/9083 reviews\n",
      "Progress: 1730/9083 reviews\n",
      "Progress: 1740/9083 reviews\n",
      "Progress: 1750/9083 reviews\n",
      "Progress: 1760/9083 reviews\n",
      "Progress: 1770/9083 reviews\n",
      "Progress: 1780/9083 reviews\n",
      "Progress: 1790/9083 reviews\n",
      "Progress: 1800/9083 reviews\n",
      "Progress: 1810/9083 reviews\n",
      "Progress: 1820/9083 reviews\n",
      "Progress: 1830/9083 reviews\n",
      "Progress: 1840/9083 reviews\n",
      "Progress: 1850/9083 reviews\n",
      "Progress: 1860/9083 reviews\n",
      "Progress: 1870/9083 reviews\n",
      "Progress: 1880/9083 reviews\n",
      "Progress: 1890/9083 reviews\n",
      "Progress: 1900/9083 reviews\n",
      "Progress: 1910/9083 reviews\n",
      "Progress: 1920/9083 reviews\n",
      "Progress: 1930/9083 reviews\n",
      "Progress: 1940/9083 reviews\n",
      "Progress: 1950/9083 reviews\n",
      "Progress: 1960/9083 reviews\n",
      "Progress: 1970/9083 reviews\n",
      "Progress: 1980/9083 reviews\n",
      "Progress: 1990/9083 reviews\n",
      "Progress: 2000/9083 reviews\n",
      "Progress: 2010/9083 reviews\n",
      "Progress: 2020/9083 reviews\n",
      "Progress: 2030/9083 reviews\n",
      "Progress: 2040/9083 reviews\n",
      "Progress: 2050/9083 reviews\n",
      "Progress: 2060/9083 reviews\n",
      "Progress: 2070/9083 reviews\n",
      "Progress: 2080/9083 reviews\n",
      "Progress: 2090/9083 reviews\n",
      "Progress: 2100/9083 reviews\n",
      "Progress: 2110/9083 reviews\n",
      "Progress: 2120/9083 reviews\n",
      "Progress: 2130/9083 reviews\n",
      "Progress: 2140/9083 reviews\n",
      "Progress: 2150/9083 reviews\n",
      "Progress: 2160/9083 reviews\n",
      "Progress: 2170/9083 reviews\n",
      "Progress: 2180/9083 reviews\n",
      "Progress: 2190/9083 reviews\n",
      "Progress: 2200/9083 reviews\n",
      "Progress: 2210/9083 reviews\n",
      "Progress: 2220/9083 reviews\n",
      "Progress: 2230/9083 reviews\n",
      "Progress: 2240/9083 reviews\n",
      "Progress: 2250/9083 reviews\n",
      "Progress: 2260/9083 reviews\n",
      "Progress: 2270/9083 reviews\n",
      "Progress: 2280/9083 reviews\n",
      "Progress: 2290/9083 reviews\n",
      "Progress: 2300/9083 reviews\n",
      "Progress: 2310/9083 reviews\n",
      "Progress: 2320/9083 reviews\n",
      "Progress: 2330/9083 reviews\n",
      "Progress: 2340/9083 reviews\n",
      "Progress: 2350/9083 reviews\n",
      "Progress: 2360/9083 reviews\n",
      "Progress: 2370/9083 reviews\n",
      "Progress: 2380/9083 reviews\n",
      "Progress: 2390/9083 reviews\n",
      "Progress: 2400/9083 reviews\n",
      "Progress: 2410/9083 reviews\n",
      "Progress: 2420/9083 reviews\n",
      "Progress: 2430/9083 reviews\n",
      "Progress: 2440/9083 reviews\n",
      "Progress: 2450/9083 reviews\n",
      "Progress: 2460/9083 reviews\n",
      "Progress: 2470/9083 reviews\n",
      "Progress: 2480/9083 reviews\n",
      "Progress: 2490/9083 reviews\n",
      "Progress: 2500/9083 reviews\n",
      "Progress: 2510/9083 reviews\n",
      "Progress: 2520/9083 reviews\n",
      "Progress: 2530/9083 reviews\n",
      "Progress: 2540/9083 reviews\n",
      "Progress: 2550/9083 reviews\n",
      "Progress: 2560/9083 reviews\n",
      "Progress: 2570/9083 reviews\n",
      "Progress: 2580/9083 reviews\n",
      "Progress: 2590/9083 reviews\n",
      "Progress: 2600/9083 reviews\n",
      "Progress: 2610/9083 reviews\n",
      "Progress: 2620/9083 reviews\n",
      "Progress: 2630/9083 reviews\n",
      "Progress: 2640/9083 reviews\n",
      "Progress: 2650/9083 reviews\n",
      "Progress: 2660/9083 reviews\n",
      "Progress: 2670/9083 reviews\n",
      "Progress: 2680/9083 reviews\n",
      "Progress: 2690/9083 reviews\n",
      "Progress: 2700/9083 reviews\n",
      "Progress: 2710/9083 reviews\n",
      "Progress: 2720/9083 reviews\n",
      "Progress: 2730/9083 reviews\n",
      "Progress: 2740/9083 reviews\n",
      "Progress: 2750/9083 reviews\n",
      "Progress: 2760/9083 reviews\n",
      "Progress: 2770/9083 reviews\n",
      "Progress: 2780/9083 reviews\n",
      "Progress: 2790/9083 reviews\n",
      "Progress: 2800/9083 reviews\n",
      "Progress: 2810/9083 reviews\n",
      "Progress: 2820/9083 reviews\n",
      "Progress: 2830/9083 reviews\n",
      "Progress: 2840/9083 reviews\n",
      "Progress: 2850/9083 reviews\n",
      "Progress: 2860/9083 reviews\n",
      "Progress: 2870/9083 reviews\n",
      "Progress: 2880/9083 reviews\n",
      "Progress: 2890/9083 reviews\n",
      "Progress: 2900/9083 reviews\n",
      "Progress: 2910/9083 reviews\n",
      "Progress: 2920/9083 reviews\n",
      "Progress: 2930/9083 reviews\n",
      "Progress: 2940/9083 reviews\n",
      "Progress: 2950/9083 reviews\n",
      "Progress: 2960/9083 reviews\n",
      "Progress: 2970/9083 reviews\n",
      "Progress: 2980/9083 reviews\n",
      "Progress: 2990/9083 reviews\n",
      "Progress: 3000/9083 reviews\n",
      "Progress: 3010/9083 reviews\n",
      "Progress: 3020/9083 reviews\n",
      "Progress: 3030/9083 reviews\n",
      "Progress: 3040/9083 reviews\n",
      "Progress: 3050/9083 reviews\n",
      "Progress: 3060/9083 reviews\n",
      "Progress: 3070/9083 reviews\n",
      "Progress: 3080/9083 reviews\n",
      "Progress: 3090/9083 reviews\n",
      "Progress: 3100/9083 reviews\n",
      "Progress: 3110/9083 reviews\n",
      "Progress: 3120/9083 reviews\n",
      "Progress: 3130/9083 reviews\n",
      "Progress: 3140/9083 reviews\n",
      "Progress: 3150/9083 reviews\n",
      "Progress: 3160/9083 reviews\n",
      "Progress: 3170/9083 reviews\n",
      "Progress: 3180/9083 reviews\n",
      "Progress: 3190/9083 reviews\n",
      "Progress: 3200/9083 reviews\n",
      "Progress: 3210/9083 reviews\n",
      "Progress: 3220/9083 reviews\n",
      "Progress: 3230/9083 reviews\n",
      "Progress: 3240/9083 reviews\n",
      "Progress: 3250/9083 reviews\n",
      "Progress: 3260/9083 reviews\n",
      "Progress: 3270/9083 reviews\n",
      "Progress: 3280/9083 reviews\n",
      "Progress: 3290/9083 reviews\n",
      "Progress: 3300/9083 reviews\n",
      "Progress: 3310/9083 reviews\n",
      "Progress: 3320/9083 reviews\n",
      "Progress: 3330/9083 reviews\n",
      "Progress: 3340/9083 reviews\n",
      "Progress: 3350/9083 reviews\n",
      "Progress: 3360/9083 reviews\n",
      "Progress: 3370/9083 reviews\n",
      "Progress: 3380/9083 reviews\n",
      "Progress: 3390/9083 reviews\n",
      "Progress: 3400/9083 reviews\n",
      "Progress: 3410/9083 reviews\n",
      "Progress: 3420/9083 reviews\n",
      "Progress: 3430/9083 reviews\n",
      "Progress: 3440/9083 reviews\n",
      "Progress: 3450/9083 reviews\n",
      "Progress: 3460/9083 reviews\n",
      "Progress: 3470/9083 reviews\n",
      "Progress: 3480/9083 reviews\n",
      "Progress: 3490/9083 reviews\n",
      "Progress: 3500/9083 reviews\n",
      "Progress: 3510/9083 reviews\n",
      "Progress: 3520/9083 reviews\n",
      "Progress: 3530/9083 reviews\n",
      "Progress: 3540/9083 reviews\n",
      "Progress: 3550/9083 reviews\n",
      "Progress: 3560/9083 reviews\n",
      "Progress: 3570/9083 reviews\n",
      "Progress: 3580/9083 reviews\n",
      "Progress: 3590/9083 reviews\n",
      "Progress: 3600/9083 reviews\n",
      "Progress: 3610/9083 reviews\n",
      "Progress: 3620/9083 reviews\n",
      "Progress: 3630/9083 reviews\n",
      "Progress: 3640/9083 reviews\n",
      "Progress: 3650/9083 reviews\n",
      "Progress: 3660/9083 reviews\n",
      "Progress: 3670/9083 reviews\n",
      "Progress: 3680/9083 reviews\n",
      "Progress: 3690/9083 reviews\n",
      "Progress: 3700/9083 reviews\n",
      "Progress: 3710/9083 reviews\n",
      "Progress: 3720/9083 reviews\n",
      "Progress: 3730/9083 reviews\n",
      "Progress: 3740/9083 reviews\n",
      "Progress: 3750/9083 reviews\n",
      "Progress: 3760/9083 reviews\n",
      "Progress: 3770/9083 reviews\n",
      "Progress: 3780/9083 reviews\n",
      "Progress: 3790/9083 reviews\n",
      "Progress: 3800/9083 reviews\n",
      "Progress: 3810/9083 reviews\n",
      "Progress: 3820/9083 reviews\n",
      "Progress: 3830/9083 reviews\n",
      "Progress: 3840/9083 reviews\n",
      "Progress: 3850/9083 reviews\n",
      "Progress: 3860/9083 reviews\n",
      "Progress: 3870/9083 reviews\n",
      "Progress: 3880/9083 reviews\n",
      "Progress: 3890/9083 reviews\n",
      "Progress: 3900/9083 reviews\n",
      "Progress: 3910/9083 reviews\n",
      "Progress: 3920/9083 reviews\n",
      "Progress: 3930/9083 reviews\n",
      "Progress: 3940/9083 reviews\n",
      "Progress: 3950/9083 reviews\n",
      "Progress: 3960/9083 reviews\n",
      "Progress: 3970/9083 reviews\n",
      "Progress: 3980/9083 reviews\n",
      "Progress: 3990/9083 reviews\n",
      "Progress: 4000/9083 reviews\n",
      "Progress: 4010/9083 reviews\n",
      "Progress: 4020/9083 reviews\n",
      "Progress: 4030/9083 reviews\n",
      "Progress: 4040/9083 reviews\n",
      "Progress: 4050/9083 reviews\n",
      "Progress: 4060/9083 reviews\n",
      "Progress: 4070/9083 reviews\n",
      "Progress: 4080/9083 reviews\n",
      "Progress: 4090/9083 reviews\n",
      "Progress: 4100/9083 reviews\n",
      "Progress: 4110/9083 reviews\n",
      "Progress: 4120/9083 reviews\n",
      "Progress: 4130/9083 reviews\n",
      "Progress: 4140/9083 reviews\n",
      "Progress: 4150/9083 reviews\n",
      "Progress: 4160/9083 reviews\n",
      "Progress: 4170/9083 reviews\n",
      "Progress: 4180/9083 reviews\n",
      "Progress: 4190/9083 reviews\n",
      "Progress: 4200/9083 reviews\n",
      "Progress: 4210/9083 reviews\n",
      "Progress: 4220/9083 reviews\n",
      "Progress: 4230/9083 reviews\n",
      "Progress: 4240/9083 reviews\n",
      "Progress: 4250/9083 reviews\n",
      "Progress: 4260/9083 reviews\n",
      "Progress: 4270/9083 reviews\n",
      "Progress: 4280/9083 reviews\n",
      "Progress: 4290/9083 reviews\n",
      "Progress: 4300/9083 reviews\n",
      "Progress: 4310/9083 reviews\n",
      "Progress: 4320/9083 reviews\n",
      "Progress: 4330/9083 reviews\n",
      "Progress: 4340/9083 reviews\n",
      "Progress: 4350/9083 reviews\n",
      "Progress: 4360/9083 reviews\n",
      "Progress: 4370/9083 reviews\n",
      "Progress: 4380/9083 reviews\n",
      "Progress: 4390/9083 reviews\n",
      "Progress: 4400/9083 reviews\n",
      "Progress: 4410/9083 reviews\n",
      "Progress: 4420/9083 reviews\n",
      "Progress: 4430/9083 reviews\n",
      "Progress: 4440/9083 reviews\n",
      "Progress: 4450/9083 reviews\n",
      "Progress: 4460/9083 reviews\n",
      "Progress: 4470/9083 reviews\n",
      "Progress: 4480/9083 reviews\n",
      "Progress: 4490/9083 reviews\n",
      "Progress: 4500/9083 reviews\n",
      "Progress: 4510/9083 reviews\n",
      "Progress: 4520/9083 reviews\n",
      "Progress: 4530/9083 reviews\n",
      "Progress: 4540/9083 reviews\n",
      "Progress: 4550/9083 reviews\n",
      "Progress: 4560/9083 reviews\n",
      "Progress: 4570/9083 reviews\n",
      "Progress: 4580/9083 reviews\n",
      "Progress: 4590/9083 reviews\n",
      "Progress: 4600/9083 reviews\n",
      "Progress: 4610/9083 reviews\n",
      "Progress: 4620/9083 reviews\n",
      "Progress: 4630/9083 reviews\n",
      "Progress: 4640/9083 reviews\n",
      "Progress: 4650/9083 reviews\n",
      "Progress: 4660/9083 reviews\n",
      "Progress: 4670/9083 reviews\n",
      "Progress: 4680/9083 reviews\n",
      "Progress: 4690/9083 reviews\n",
      "Progress: 4700/9083 reviews\n",
      "Progress: 4710/9083 reviews\n",
      "Progress: 4720/9083 reviews\n",
      "Progress: 4730/9083 reviews\n",
      "Progress: 4740/9083 reviews\n",
      "Progress: 4750/9083 reviews\n",
      "Progress: 4760/9083 reviews\n",
      "Progress: 4770/9083 reviews\n",
      "Progress: 4780/9083 reviews\n",
      "Progress: 4790/9083 reviews\n",
      "Progress: 4800/9083 reviews\n",
      "Progress: 4810/9083 reviews\n",
      "Progress: 4820/9083 reviews\n",
      "Progress: 4830/9083 reviews\n",
      "Progress: 4840/9083 reviews\n",
      "Progress: 4850/9083 reviews\n",
      "Progress: 4860/9083 reviews\n",
      "Progress: 4870/9083 reviews\n",
      "Progress: 4880/9083 reviews\n",
      "Progress: 4890/9083 reviews\n",
      "Progress: 4900/9083 reviews\n",
      "Progress: 4910/9083 reviews\n",
      "Progress: 4920/9083 reviews\n",
      "Progress: 4930/9083 reviews\n",
      "Progress: 4940/9083 reviews\n",
      "Progress: 4950/9083 reviews\n",
      "Progress: 4960/9083 reviews\n",
      "Progress: 4970/9083 reviews\n",
      "Progress: 4980/9083 reviews\n",
      "Progress: 4990/9083 reviews\n",
      "Progress: 5000/9083 reviews\n",
      "Progress: 5010/9083 reviews\n",
      "Progress: 5020/9083 reviews\n",
      "Progress: 5030/9083 reviews\n",
      "Progress: 5040/9083 reviews\n",
      "Progress: 5050/9083 reviews\n",
      "Progress: 5060/9083 reviews\n",
      "Progress: 5070/9083 reviews\n",
      "Progress: 5080/9083 reviews\n",
      "Progress: 5090/9083 reviews\n",
      "Progress: 5100/9083 reviews\n",
      "Progress: 5110/9083 reviews\n",
      "Progress: 5120/9083 reviews\n",
      "Progress: 5130/9083 reviews\n",
      "Progress: 5140/9083 reviews\n",
      "Progress: 5150/9083 reviews\n",
      "Progress: 5160/9083 reviews\n",
      "Progress: 5170/9083 reviews\n",
      "Progress: 5180/9083 reviews\n",
      "Progress: 5190/9083 reviews\n",
      "Progress: 5200/9083 reviews\n",
      "Progress: 5210/9083 reviews\n",
      "Progress: 5220/9083 reviews\n",
      "Progress: 5230/9083 reviews\n",
      "Progress: 5240/9083 reviews\n",
      "Progress: 5250/9083 reviews\n",
      "Progress: 5260/9083 reviews\n",
      "Progress: 5270/9083 reviews\n",
      "Progress: 5280/9083 reviews\n",
      "Progress: 5290/9083 reviews\n",
      "Progress: 5300/9083 reviews\n",
      "Progress: 5310/9083 reviews\n",
      "Progress: 5320/9083 reviews\n",
      "Progress: 5330/9083 reviews\n",
      "Progress: 5340/9083 reviews\n",
      "Progress: 5350/9083 reviews\n",
      "Progress: 5360/9083 reviews\n",
      "Progress: 5370/9083 reviews\n",
      "Progress: 5380/9083 reviews\n",
      "Progress: 5390/9083 reviews\n",
      "Progress: 5400/9083 reviews\n",
      "Progress: 5410/9083 reviews\n",
      "Progress: 5420/9083 reviews\n",
      "Progress: 5430/9083 reviews\n",
      "Progress: 5440/9083 reviews\n",
      "Progress: 5450/9083 reviews\n",
      "Progress: 5460/9083 reviews\n",
      "Progress: 5470/9083 reviews\n",
      "Progress: 5480/9083 reviews\n",
      "Progress: 5490/9083 reviews\n",
      "Progress: 5500/9083 reviews\n",
      "Progress: 5510/9083 reviews\n",
      "Progress: 5520/9083 reviews\n",
      "Progress: 5530/9083 reviews\n",
      "Progress: 5540/9083 reviews\n",
      "Progress: 5550/9083 reviews\n",
      "Progress: 5560/9083 reviews\n",
      "Progress: 5570/9083 reviews\n",
      "Progress: 5580/9083 reviews\n",
      "Progress: 5590/9083 reviews\n",
      "Progress: 5600/9083 reviews\n",
      "Progress: 5610/9083 reviews\n",
      "Progress: 5620/9083 reviews\n",
      "Progress: 5630/9083 reviews\n",
      "Progress: 5640/9083 reviews\n",
      "Progress: 5650/9083 reviews\n",
      "Progress: 5660/9083 reviews\n",
      "Progress: 5670/9083 reviews\n",
      "Progress: 5680/9083 reviews\n",
      "Progress: 5690/9083 reviews\n",
      "Progress: 5700/9083 reviews\n",
      "Progress: 5710/9083 reviews\n",
      "Progress: 5720/9083 reviews\n",
      "Progress: 5730/9083 reviews\n",
      "Progress: 5740/9083 reviews\n",
      "Progress: 5750/9083 reviews\n",
      "Progress: 5760/9083 reviews\n",
      "Progress: 5770/9083 reviews\n",
      "Progress: 5780/9083 reviews\n",
      "Progress: 5790/9083 reviews\n",
      "Progress: 5800/9083 reviews\n",
      "Progress: 5810/9083 reviews\n",
      "Progress: 5820/9083 reviews\n",
      "Progress: 5830/9083 reviews\n",
      "Progress: 5840/9083 reviews\n",
      "Progress: 5850/9083 reviews\n",
      "Progress: 5860/9083 reviews\n",
      "Progress: 5870/9083 reviews\n",
      "Progress: 5880/9083 reviews\n",
      "Progress: 5890/9083 reviews\n",
      "Progress: 5900/9083 reviews\n",
      "Progress: 5910/9083 reviews\n",
      "Progress: 5920/9083 reviews\n",
      "Progress: 5930/9083 reviews\n",
      "Progress: 5940/9083 reviews\n",
      "Progress: 5950/9083 reviews\n",
      "Progress: 5960/9083 reviews\n",
      "Progress: 5970/9083 reviews\n",
      "Progress: 5980/9083 reviews\n",
      "Progress: 5990/9083 reviews\n",
      "Progress: 6000/9083 reviews\n",
      "Progress: 6010/9083 reviews\n",
      "Progress: 6020/9083 reviews\n",
      "Progress: 6030/9083 reviews\n",
      "Progress: 6040/9083 reviews\n",
      "Progress: 6050/9083 reviews\n",
      "Progress: 6060/9083 reviews\n",
      "Progress: 6070/9083 reviews\n",
      "Progress: 6080/9083 reviews\n",
      "Progress: 6090/9083 reviews\n",
      "Progress: 6100/9083 reviews\n",
      "Progress: 6110/9083 reviews\n",
      "Progress: 6120/9083 reviews\n",
      "Progress: 6130/9083 reviews\n",
      "Progress: 6140/9083 reviews\n",
      "Progress: 6150/9083 reviews\n",
      "Progress: 6160/9083 reviews\n",
      "Progress: 6170/9083 reviews\n",
      "Progress: 6180/9083 reviews\n",
      "Progress: 6190/9083 reviews\n",
      "Progress: 6200/9083 reviews\n",
      "Progress: 6210/9083 reviews\n",
      "Progress: 6220/9083 reviews\n",
      "Progress: 6230/9083 reviews\n",
      "Progress: 6240/9083 reviews\n",
      "Progress: 6250/9083 reviews\n",
      "Progress: 6260/9083 reviews\n",
      "Progress: 6270/9083 reviews\n",
      "Progress: 6280/9083 reviews\n",
      "Progress: 6290/9083 reviews\n",
      "Progress: 6300/9083 reviews\n",
      "Progress: 6310/9083 reviews\n",
      "Progress: 6320/9083 reviews\n",
      "Progress: 6330/9083 reviews\n",
      "Progress: 6340/9083 reviews\n",
      "Progress: 6350/9083 reviews\n",
      "Progress: 6360/9083 reviews\n",
      "Progress: 6370/9083 reviews\n",
      "Progress: 6380/9083 reviews\n",
      "Progress: 6390/9083 reviews\n",
      "Progress: 6400/9083 reviews\n",
      "Progress: 6410/9083 reviews\n",
      "Progress: 6420/9083 reviews\n",
      "Progress: 6430/9083 reviews\n",
      "Progress: 6440/9083 reviews\n",
      "Progress: 6450/9083 reviews\n",
      "Progress: 6460/9083 reviews\n",
      "Progress: 6470/9083 reviews\n",
      "Progress: 6480/9083 reviews\n",
      "Progress: 6490/9083 reviews\n",
      "Progress: 6500/9083 reviews\n",
      "Progress: 6510/9083 reviews\n",
      "Progress: 6520/9083 reviews\n",
      "Progress: 6530/9083 reviews\n",
      "Progress: 6540/9083 reviews\n",
      "Progress: 6550/9083 reviews\n",
      "Progress: 6560/9083 reviews\n",
      "Progress: 6570/9083 reviews\n",
      "Progress: 6580/9083 reviews\n",
      "Progress: 6590/9083 reviews\n",
      "Progress: 6600/9083 reviews\n",
      "Progress: 6610/9083 reviews\n",
      "Progress: 6620/9083 reviews\n",
      "Progress: 6630/9083 reviews\n",
      "Progress: 6640/9083 reviews\n",
      "Progress: 6650/9083 reviews\n",
      "Progress: 6660/9083 reviews\n",
      "Progress: 6670/9083 reviews\n",
      "Progress: 6680/9083 reviews\n",
      "Progress: 6690/9083 reviews\n",
      "Progress: 6700/9083 reviews\n",
      "Progress: 6710/9083 reviews\n",
      "Progress: 6720/9083 reviews\n",
      "Progress: 6730/9083 reviews\n",
      "Progress: 6740/9083 reviews\n",
      "Progress: 6750/9083 reviews\n",
      "Progress: 6760/9083 reviews\n",
      "Progress: 6770/9083 reviews\n",
      "Progress: 6780/9083 reviews\n",
      "Progress: 6790/9083 reviews\n",
      "Progress: 6800/9083 reviews\n",
      "Progress: 6810/9083 reviews\n",
      "Progress: 6820/9083 reviews\n",
      "Progress: 6830/9083 reviews\n",
      "Progress: 6840/9083 reviews\n",
      "Progress: 6850/9083 reviews\n",
      "Progress: 6860/9083 reviews\n",
      "Progress: 6870/9083 reviews\n",
      "Progress: 6880/9083 reviews\n",
      "Progress: 6890/9083 reviews\n",
      "Progress: 6900/9083 reviews\n",
      "Progress: 6910/9083 reviews\n",
      "Progress: 6920/9083 reviews\n",
      "Progress: 6930/9083 reviews\n",
      "Progress: 6940/9083 reviews\n",
      "Progress: 6950/9083 reviews\n",
      "Progress: 6960/9083 reviews\n",
      "Progress: 6970/9083 reviews\n",
      "Progress: 6980/9083 reviews\n",
      "Progress: 6990/9083 reviews\n",
      "Progress: 7000/9083 reviews\n",
      "Progress: 7010/9083 reviews\n",
      "Progress: 7020/9083 reviews\n",
      "Progress: 7030/9083 reviews\n",
      "Progress: 7040/9083 reviews\n",
      "Progress: 7050/9083 reviews\n",
      "Progress: 7060/9083 reviews\n",
      "Progress: 7070/9083 reviews\n",
      "Progress: 7080/9083 reviews\n",
      "Progress: 7090/9083 reviews\n",
      "Progress: 7100/9083 reviews\n",
      "Progress: 7110/9083 reviews\n",
      "Progress: 7120/9083 reviews\n",
      "Progress: 7130/9083 reviews\n",
      "Progress: 7140/9083 reviews\n",
      "Progress: 7150/9083 reviews\n",
      "Progress: 7160/9083 reviews\n",
      "Progress: 7170/9083 reviews\n",
      "Progress: 7180/9083 reviews\n",
      "Progress: 7190/9083 reviews\n",
      "Progress: 7200/9083 reviews\n",
      "Progress: 7210/9083 reviews\n",
      "Progress: 7220/9083 reviews\n",
      "Progress: 7230/9083 reviews\n",
      "Progress: 7240/9083 reviews\n",
      "Progress: 7250/9083 reviews\n",
      "Progress: 7260/9083 reviews\n",
      "Progress: 7270/9083 reviews\n",
      "Progress: 7280/9083 reviews\n",
      "Progress: 7290/9083 reviews\n",
      "Progress: 7300/9083 reviews\n",
      "Progress: 7310/9083 reviews\n",
      "Progress: 7320/9083 reviews\n",
      "Progress: 7330/9083 reviews\n",
      "Progress: 7340/9083 reviews\n",
      "Progress: 7350/9083 reviews\n",
      "Progress: 7360/9083 reviews\n",
      "Progress: 7370/9083 reviews\n",
      "Progress: 7380/9083 reviews\n",
      "Progress: 7390/9083 reviews\n",
      "Progress: 7400/9083 reviews\n",
      "Progress: 7410/9083 reviews\n",
      "Progress: 7420/9083 reviews\n",
      "Progress: 7430/9083 reviews\n",
      "Progress: 7440/9083 reviews\n",
      "Progress: 7450/9083 reviews\n",
      "Progress: 7460/9083 reviews\n",
      "Progress: 7470/9083 reviews\n",
      "Progress: 7480/9083 reviews\n",
      "Progress: 7490/9083 reviews\n",
      "Progress: 7500/9083 reviews\n",
      "Progress: 7510/9083 reviews\n",
      "Progress: 7520/9083 reviews\n",
      "Progress: 7530/9083 reviews\n",
      "Progress: 7540/9083 reviews\n",
      "Progress: 7550/9083 reviews\n",
      "Progress: 7560/9083 reviews\n",
      "Progress: 7570/9083 reviews\n",
      "Progress: 7580/9083 reviews\n",
      "Progress: 7590/9083 reviews\n",
      "Progress: 7600/9083 reviews\n",
      "Progress: 7610/9083 reviews\n",
      "Progress: 7620/9083 reviews\n",
      "Progress: 7630/9083 reviews\n",
      "Progress: 7640/9083 reviews\n",
      "Progress: 7650/9083 reviews\n",
      "Progress: 7660/9083 reviews\n",
      "Progress: 7670/9083 reviews\n",
      "Progress: 7680/9083 reviews\n",
      "Progress: 7690/9083 reviews\n",
      "Progress: 7700/9083 reviews\n",
      "Progress: 7710/9083 reviews\n",
      "Progress: 7720/9083 reviews\n",
      "Progress: 7730/9083 reviews\n",
      "Progress: 7740/9083 reviews\n",
      "Progress: 7750/9083 reviews\n",
      "Progress: 7760/9083 reviews\n",
      "Progress: 7770/9083 reviews\n",
      "Progress: 7780/9083 reviews\n",
      "Progress: 7790/9083 reviews\n",
      "Progress: 7800/9083 reviews\n",
      "Progress: 7810/9083 reviews\n",
      "Progress: 7820/9083 reviews\n",
      "Progress: 7830/9083 reviews\n",
      "Progress: 7840/9083 reviews\n",
      "Progress: 7850/9083 reviews\n",
      "Progress: 7860/9083 reviews\n",
      "Progress: 7870/9083 reviews\n",
      "Progress: 7880/9083 reviews\n",
      "Progress: 7890/9083 reviews\n",
      "Progress: 7900/9083 reviews\n",
      "Progress: 7910/9083 reviews\n",
      "Progress: 7920/9083 reviews\n",
      "Progress: 7930/9083 reviews\n",
      "Progress: 7940/9083 reviews\n",
      "Progress: 7950/9083 reviews\n",
      "Progress: 7960/9083 reviews\n",
      "Progress: 7970/9083 reviews\n",
      "Progress: 7980/9083 reviews\n",
      "Progress: 7990/9083 reviews\n",
      "Progress: 8000/9083 reviews\n",
      "Progress: 8010/9083 reviews\n",
      "Progress: 8020/9083 reviews\n",
      "Progress: 8030/9083 reviews\n",
      "Progress: 8040/9083 reviews\n",
      "Progress: 8050/9083 reviews\n",
      "Progress: 8060/9083 reviews\n",
      "Progress: 8070/9083 reviews\n",
      "Progress: 8080/9083 reviews\n",
      "Progress: 8090/9083 reviews\n",
      "Progress: 8100/9083 reviews\n",
      "Progress: 8110/9083 reviews\n",
      "Progress: 8120/9083 reviews\n",
      "Progress: 8130/9083 reviews\n",
      "Progress: 8140/9083 reviews\n",
      "Progress: 8150/9083 reviews\n",
      "Progress: 8160/9083 reviews\n",
      "Progress: 8170/9083 reviews\n",
      "Progress: 8180/9083 reviews\n",
      "Progress: 8190/9083 reviews\n",
      "Progress: 8200/9083 reviews\n",
      "Progress: 8210/9083 reviews\n",
      "Progress: 8220/9083 reviews\n",
      "Progress: 8230/9083 reviews\n",
      "Progress: 8240/9083 reviews\n",
      "Progress: 8250/9083 reviews\n",
      "Progress: 8260/9083 reviews\n",
      "Progress: 8270/9083 reviews\n",
      "Progress: 8280/9083 reviews\n",
      "Progress: 8290/9083 reviews\n",
      "Progress: 8300/9083 reviews\n",
      "Progress: 8310/9083 reviews\n",
      "Progress: 8320/9083 reviews\n",
      "Progress: 8330/9083 reviews\n",
      "Progress: 8340/9083 reviews\n",
      "Progress: 8350/9083 reviews\n",
      "Progress: 8360/9083 reviews\n",
      "Progress: 8370/9083 reviews\n",
      "Progress: 8380/9083 reviews\n",
      "Progress: 8390/9083 reviews\n",
      "Progress: 8400/9083 reviews\n",
      "Progress: 8410/9083 reviews\n",
      "Progress: 8420/9083 reviews\n",
      "Progress: 8430/9083 reviews\n",
      "Progress: 8440/9083 reviews\n",
      "Progress: 8450/9083 reviews\n",
      "Progress: 8460/9083 reviews\n",
      "Progress: 8470/9083 reviews\n",
      "Progress: 8480/9083 reviews\n",
      "Progress: 8490/9083 reviews\n",
      "Progress: 8500/9083 reviews\n",
      "Progress: 8510/9083 reviews\n",
      "Progress: 8520/9083 reviews\n",
      "Progress: 8530/9083 reviews\n",
      "Progress: 8540/9083 reviews\n",
      "Progress: 8550/9083 reviews\n",
      "Progress: 8560/9083 reviews\n",
      "Progress: 8570/9083 reviews\n",
      "Progress: 8580/9083 reviews\n",
      "Progress: 8590/9083 reviews\n",
      "Progress: 8600/9083 reviews\n",
      "Progress: 8610/9083 reviews\n",
      "Progress: 8620/9083 reviews\n",
      "Progress: 8630/9083 reviews\n",
      "Progress: 8640/9083 reviews\n",
      "Progress: 8650/9083 reviews\n",
      "Progress: 8660/9083 reviews\n",
      "Progress: 8670/9083 reviews\n",
      "Progress: 8680/9083 reviews\n",
      "Progress: 8690/9083 reviews\n",
      "Progress: 8700/9083 reviews\n",
      "Progress: 8710/9083 reviews\n",
      "Progress: 8720/9083 reviews\n",
      "Progress: 8730/9083 reviews\n",
      "Progress: 8740/9083 reviews\n",
      "Progress: 8750/9083 reviews\n",
      "Progress: 8760/9083 reviews\n",
      "Progress: 8770/9083 reviews\n",
      "Progress: 8780/9083 reviews\n",
      "Progress: 8790/9083 reviews\n",
      "Progress: 8800/9083 reviews\n",
      "Progress: 8810/9083 reviews\n",
      "Progress: 8820/9083 reviews\n",
      "Progress: 8830/9083 reviews\n",
      "Progress: 8840/9083 reviews\n",
      "Progress: 8850/9083 reviews\n",
      "Progress: 8860/9083 reviews\n",
      "Progress: 8870/9083 reviews\n",
      "Progress: 8880/9083 reviews\n",
      "Progress: 8890/9083 reviews\n",
      "Progress: 8900/9083 reviews\n",
      "Progress: 8910/9083 reviews\n",
      "Progress: 8920/9083 reviews\n",
      "Progress: 8930/9083 reviews\n",
      "Progress: 8940/9083 reviews\n",
      "Progress: 8950/9083 reviews\n",
      "Progress: 8960/9083 reviews\n",
      "Progress: 8970/9083 reviews\n",
      "Progress: 8980/9083 reviews\n",
      "Progress: 8990/9083 reviews\n",
      "Progress: 9000/9083 reviews\n",
      "Progress: 9010/9083 reviews\n",
      "Progress: 9020/9083 reviews\n",
      "Progress: 9030/9083 reviews\n",
      "Progress: 9040/9083 reviews\n",
      "Progress: 9050/9083 reviews\n",
      "Progress: 9060/9083 reviews\n",
      "Progress: 9070/9083 reviews\n",
      "Progress: 9080/9083 reviews\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'absa_output\\Nov20'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 159\u001b[39m\n\u001b[32m    157\u001b[39m         results_df.to_csv(output_csv, mode=\u001b[33m'\u001b[39m\u001b[33ma\u001b[39m\u001b[33m'\u001b[39m, header=\u001b[38;5;28;01mFalse\u001b[39;00m, index=\u001b[38;5;28;01mFalse\u001b[39;00m, encoding=\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    158\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m         \u001b[43mresults_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_csv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mâœ“ Saved \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(results)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m new reviews to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_csv\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\util\\_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\generic.py:3986\u001b[39m, in \u001b[36mNDFrame.to_csv\u001b[39m\u001b[34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[39m\n\u001b[32m   3975\u001b[39m df = \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.to_frame()\n\u001b[32m   3977\u001b[39m formatter = DataFrameFormatter(\n\u001b[32m   3978\u001b[39m     frame=df,\n\u001b[32m   3979\u001b[39m     header=header,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3983\u001b[39m     decimal=decimal,\n\u001b[32m   3984\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m3986\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3987\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3988\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3989\u001b[39m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3990\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3991\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3992\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3993\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3994\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3995\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3996\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3997\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3999\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4000\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4001\u001b[39m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4002\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4003\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[39m, in \u001b[36mDataFrameRenderer.to_csv\u001b[39m\u001b[34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[39m\n\u001b[32m    993\u001b[39m     created_buffer = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    995\u001b[39m csv_formatter = CSVFormatter(\n\u001b[32m    996\u001b[39m     path_or_buf=path_or_buf,\n\u001b[32m    997\u001b[39m     lineterminator=lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1012\u001b[39m     formatter=\u001b[38;5;28mself\u001b[39m.fmt,\n\u001b[32m   1013\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m \u001b[43mcsv_formatter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[32m   1017\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[39m, in \u001b[36mCSVFormatter.save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03mCreate the writer & save.\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    250\u001b[39m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[32m    259\u001b[39m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;28mself\u001b[39m.writer = csvlib.writer(\n\u001b[32m    261\u001b[39m         handles.handle,\n\u001b[32m    262\u001b[39m         lineterminator=\u001b[38;5;28mself\u001b[39m.lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m    267\u001b[39m         quotechar=\u001b[38;5;28mself\u001b[39m.quotechar,\n\u001b[32m    268\u001b[39m     )\n\u001b[32m    270\u001b[39m     \u001b[38;5;28mself\u001b[39m._save()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\common.py:749\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    747\u001b[39m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[32m--> \u001b[39m\u001b[32m749\u001b[39m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    751\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[32m    752\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m compression != \u001b[33m\"\u001b[39m\u001b[33mzstd\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    753\u001b[39m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\common.py:616\u001b[39m, in \u001b[36mcheck_parent_directory\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m    614\u001b[39m parent = Path(path).parent\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent.is_dir():\n\u001b[32m--> \u001b[39m\u001b[32m616\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33mrf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot save file into a non-existent directory: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mOSError\u001b[39m: Cannot save file into a non-existent directory: 'absa_output\\Nov20'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ============================================================================\n",
    "# SETUP AND PATCHING\n",
    "# ============================================================================\n",
    "# Apply the nuclear patch for DeBERTa tokenizer\n",
    "original_getattr = DebertaV2TokenizerFast.__getattr__ if hasattr(DebertaV2TokenizerFast, '__getattr__') else None\n",
    "\n",
    "def custom_getattr(self, name):\n",
    "    defaults = {\n",
    "        'bos_token': None,\n",
    "        'eos_token': None,\n",
    "        'split_special_tokens': False,\n",
    "        'cls_token': '[CLS]',\n",
    "        'sep_token': '[SEP]',\n",
    "        'unk_token': '[UNK]',\n",
    "        'pad_token': '[PAD]',\n",
    "        'mask_token': '[MASK]',\n",
    "    }\n",
    "    \n",
    "    if name.endswith('_id') and name[:-3] in defaults:\n",
    "        token_name = name[:-3]\n",
    "        token = defaults.get(token_name)\n",
    "        if token and hasattr(self, 'convert_tokens_to_ids'):\n",
    "            try:\n",
    "                return self.convert_tokens_to_ids(token)\n",
    "            except:\n",
    "                return 0\n",
    "        return 0\n",
    "    \n",
    "    if name in defaults:\n",
    "        private_name = f'_{name}'\n",
    "        if hasattr(self, private_name):\n",
    "            return getattr(self, private_name)\n",
    "        return defaults[name]\n",
    "    \n",
    "    if original_getattr:\n",
    "        return original_getattr(self, name)\n",
    "    \n",
    "    raise AttributeError(f\"'{type(self).__name__}' object has no attribute '{name}'\")\n",
    "\n",
    "DebertaV2TokenizerFast.__getattr__ = custom_getattr\n",
    "\n",
    "# Initialize the aspect extractor\n",
    "print(\"\\nLoading ABSA model...\")\n",
    "checkpoint_path = os.path.join(\n",
    "    'checkpoints', \n",
    "    'ATEPC_ENGLISH_CHECKPOINT', \n",
    "    'fast_lcf_atepc_English_cdw_apcacc_82.36_apcf1_81.89_atef1_75.43'\n",
    ")\n",
    "aspect_extractor = ATEPC.AspectExtractor(checkpoint_path, auto_device=True)\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD AND FILTER DATA\n",
    "# ============================================================================\n",
    "print(\"\\nLoading dataset...\")\n",
    "if df['timestamp'].dtype == 'O' or not pd.api.types.is_datetime64_any_dtype(df['timestamp']):\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
    "\n",
    "df_filtered = df[df['timestamp'].dt.month == selected_month].copy()\n",
    "print(f'Filtered rows for month {selected_month}: {len(df_filtered)}')\n",
    "\n",
    "# ============================================================================\n",
    "# CSV SETUP FOR RESUMABLE PROCESSING\n",
    "# ============================================================================\n",
    "output_csv = os.path.join(\"absa_output\" ,\n",
    "                            f\"{datetime(1900, selected_month, 1).strftime('%b')}\"\n",
    "                            f\"{str(selected_year)[-2:]}\", \n",
    "                            f\"beauty_absa_results.csv\")\n",
    "processed_ids = set()\n",
    "\n",
    "# Check if CSV already exists and load processed IDs\n",
    "if os.path.exists(output_csv):\n",
    "    print(f\"\\nFound existing results file: {output_csv}\")\n",
    "    existing_df = pd.read_csv(output_csv, dtype={'review_id': str})\n",
    "    processed_ids = set(existing_df['review_id'].astype(str).unique())\n",
    "    print(f\"Resuming from {len(processed_ids)} already processed reviews\")\n",
    "    start_row = len(processed_ids)\n",
    "else:\n",
    "    print(f\"\\nCreating new results file: {output_csv}\")\n",
    "    start_row = 0\n",
    "\n",
    "# ============================================================================\n",
    "# PROCESS REVIEWS WITH ABSA\n",
    "# ============================================================================\n",
    "print(f\"\\nProcessing reviews with ABSA...\\n\")\n",
    "results = []\n",
    "total_to_process = len(df_filtered)\n",
    "\n",
    "for idx, (row_idx, row) in enumerate(df_filtered.iterrows()):\n",
    "    review_id = str(row_idx)\n",
    "    \n",
    "    # Skip if already processed\n",
    "    if review_id in processed_ids:\n",
    "        continue\n",
    "\n",
    "    review_text = row['title'] + \" \" + row['text'] if not pd.isna(row['title']) and not pd.isna(row['text']) else row['text'] if not pd.isna(row['text']) else row['title'] if not pd.isna(row['title']) else \"\"\n",
    "    \n",
    "    # Skip empty reviews    \n",
    "    if not review_text.strip():\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        prediction = aspect_extractor.predict(\n",
    "            review_text,\n",
    "            save_result=False,\n",
    "            print_result=False,\n",
    "            ignore_error=True\n",
    "        )\n",
    "        \n",
    "        aspects = []\n",
    "        if prediction and isinstance(prediction, dict):\n",
    "            if 'aspect' in prediction and 'sentiment' in prediction:\n",
    "                for i, aspect in enumerate(prediction['aspect']):\n",
    "                    sentiment = prediction['sentiment'][i] if i < len(prediction['sentiment']) else 'Neutral'\n",
    "                    confidence = prediction.get('confidence', [1.0])[i] if i < len(prediction.get('confidence', [1.0])) else 1.0\n",
    "                    aspects.append({\n",
    "                        'term': aspect,\n",
    "                        'sentiment': sentiment,\n",
    "                        'confidence': confidence\n",
    "                    })\n",
    "        \n",
    "        result_dict = {\n",
    "            'review_id': review_id,\n",
    "            'rating': row.get('rating', 0),\n",
    "            'text': review_text[:500],  # Truncate text for CSV storage\n",
    "            'timestamp': row.get('timestamp', ''),\n",
    "            'user_id': row.get('user_id', ''),\n",
    "            'parent_asin': row.get('parent_asin', ''),\n",
    "            'aspects_json': json.dumps(aspects),\n",
    "        }\n",
    "        \n",
    "        results.append(result_dict)\n",
    "        \n",
    "        if len(results) % 10 == 0:\n",
    "            print(f\"Progress: {start_row + len(results)}/{total_to_process} reviews\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing review {review_id}: {str(e)[:50]}\")\n",
    "        result_dict = {\n",
    "            'review_id': review_id,\n",
    "            'rating': row.get('rating', 0),\n",
    "            'text': review_text[:500],\n",
    "            'timestamp': row.get('timestamp', ''),\n",
    "            'user_id': row.get('user_id', ''),\n",
    "            'parent_asin': row.get('parent_asin', ''),\n",
    "            'aspects_json': '[]',\n",
    "        }\n",
    "        results.append(result_dict)\n",
    "\n",
    "# ============================================================================\n",
    "# SAVE TO CSV (APPEND MODE)\n",
    "# ============================================================================\n",
    "if results:\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    if os.path.exists(output_csv):\n",
    "        results_df.to_csv(output_csv, mode='a', header=False, index=False, encoding='utf-8')\n",
    "    else:\n",
    "        results_df.to_csv(output_csv, index=False, encoding='utf-8')\n",
    "    \n",
    "    print(f\"\\nâœ“ Saved {len(results)} new reviews to {output_csv}\")\n",
    "else:\n",
    "    print(\"\\nNo new reviews to process\")\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD ALL RESULTS FOR ANALYSIS\n",
    "# ============================================================================\n",
    "all_results_df = pd.read_csv(output_csv, dtype={'review_id': str})\n",
    "print(f\"Total reviews in file: {len(all_results_df)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# GENERATE ANALYSIS SUMMARY\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BEAUTY PRODUCT ANALYSIS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "all_aspects = {}\n",
    "sentiment_counts = {'Positive': 0, 'Negative': 0, 'Neutral': 0}\n",
    "\n",
    "for _, row in all_results_df.iterrows():\n",
    "    try:\n",
    "        aspects = json.loads(row['aspects_json'])\n",
    "        for aspect in aspects:\n",
    "            term = aspect['term']\n",
    "            sentiment = aspect['sentiment']\n",
    "            \n",
    "            if term not in all_aspects:\n",
    "                all_aspects[term] = {'Positive': 0, 'Negative': 0, 'Neutral': 0, 'total': 0}\n",
    "            \n",
    "            all_aspects[term][sentiment] += 1\n",
    "            all_aspects[term]['total'] += 1\n",
    "            sentiment_counts[sentiment] += 1\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "print(f\"\\nTop 10 Most Mentioned Beauty Aspects:\")\n",
    "if all_aspects:\n",
    "    sorted_aspects = sorted(all_aspects.items(), key=lambda x: x[1]['total'], reverse=True)[:10]\n",
    "    for term, counts in sorted_aspects:\n",
    "        if counts['total'] > 0:\n",
    "            sentiment_score = (counts['Positive'] - counts['Negative']) / counts['total']\n",
    "            print(f\"  {term}: {counts['total']} mentions (Score: {sentiment_score:.2f})\")\n",
    "            print(f\"    Positive: {counts['Positive']}, Negative: {counts['Negative']}, Neutral: {counts['Neutral']}\")\n",
    "else:\n",
    "    print(\"  No aspects detected in the processed reviews.\")\n",
    "\n",
    "print(f\"\\nOverall Beauty Product Sentiment Distribution:\")\n",
    "print(f\"  Positive: {sentiment_counts['Positive']}\")\n",
    "print(f\"  Negative: {sentiment_counts['Negative']}\")\n",
    "print(f\"  Neutral: {sentiment_counts['Neutral']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"âœ“ Analysis complete! Results saved to {output_csv}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f5173bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_save = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5d9c3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ“ Saved 9083 new reviews to absa_output\\Nov20\\beauty_absa_results.csv\n"
     ]
    }
   ],
   "source": [
    "if results:\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    if os.path.exists(output_csv):\n",
    "        results_df.to_csv(output_csv, mode='a', header=False, index=False, encoding='utf-8')\n",
    "    else:\n",
    "        results_df.to_csv(output_csv, index=False, encoding='utf-8')\n",
    "    \n",
    "    print(f\"\\nâœ“ Saved {len(results)} new reviews to {output_csv}\")\n",
    "else:\n",
    "    print(\"\\nNo new reviews to process\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
